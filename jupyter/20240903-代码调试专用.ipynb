{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T08:49:17.308908Z",
     "start_time": "2024-09-03T08:49:17.286472Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not \"CHDIR_FLAG\" in dir():\n",
    "    os.chdir(\"../\")\n",
    "    CHDIR_FLAG = True\n",
    "else:\n",
    "    assert CHDIR_FLAG is True, CHDIR_FLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T08:49:20.171083Z",
     "start_time": "2024-09-03T08:49:17.312218Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py39-adapters\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "E:\\Anaconda3\\envs\\py39-adapters\\lib\\site-packages\\transformers\\adapters\\__init__.py:27: FutureWarning: The `adapter-transformers` package is deprecated and replaced by the `adapters` package. See https://docs.adapterhub.ml/transitioning.html.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @author : caoyang\n",
    "# @email: caoyang@stu.sufe.edu.cn\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from settings import DATA_DIR, LOG_DIR, MODEL_ROOT, DATA_SUMMARY, MODEL_SUMMARY\n",
    "\n",
    "from src.datasets import RaceDataset, DreamDataset, SquadDataset, HotpotqaDataset, MusiqueDataset, TriviaqaDataset\n",
    "from src.models import RobertaLargeFinetunedRace\n",
    "from src.tools.easy import initialize_logger, terminate_logger\n",
    "\n",
    "def test_yield_batch():\n",
    "    # data_dir = r\"D:\\data\"\t# Lab PC\n",
    "    # data_dir = r\"D:\\resource\\data\"\t# Region Laptop\n",
    "    data_dir = DATA_DIR\t# default\n",
    "    data_dir_race = DATA_SUMMARY[\"RACE\"][\"path\"]\n",
    "    data_dir_dream = DATA_SUMMARY[\"DREAM\"][\"path\"]\n",
    "    data_dir_squad = DATA_SUMMARY[\"SQuAD\"][\"path\"]\n",
    "    data_dir_hotpotqa = DATA_SUMMARY[\"HotpotQA\"][\"path\"]\n",
    "    data_dir_musique = DATA_SUMMARY[\"Musique\"][\"path\"]\n",
    "    data_dir_triviaqa = DATA_SUMMARY[\"TriviaQA\"][\"path\"]\n",
    "\n",
    "    # RACE\n",
    "    def _test_race():\n",
    "        print(_test_race.__name__)\n",
    "        dataset = RaceDataset(data_dir=data_dir_race)\n",
    "        for batch in dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"], difficulties=[\"high\"]):\n",
    "            pass\n",
    "    # DREAM\n",
    "    def _test_dream():\n",
    "        print(_test_dream.__name__)\n",
    "        dataset = DreamDataset(data_dir=data_dir_dream)\n",
    "        for batch in dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"]):\n",
    "            pass\n",
    "    # SQuAD\n",
    "    def _test_squad():\n",
    "        print(_test_squad.__name__)\n",
    "        dataset = SquadDataset(data_dir=data_dir_squad)\n",
    "        versions = [\"1.1\"]\n",
    "        types = [\"train\", \"dev\"]\n",
    "        for version in versions:\n",
    "            for type_ in types:\n",
    "                for i, batch in enumerate(dataset.yield_batch(batch_size=2, version=version, type_=type_)):\n",
    "                    if i > 5:\n",
    "                        break\n",
    "                    print(batch)\n",
    "    # HotpotQA\n",
    "    def _test_hotpotqa():\n",
    "        print(_test_hotpotqa.__name__)\n",
    "        dataset = HotpotqaDataset(data_dir=data_dir_hotpotqa)\n",
    "        filenames = [\"hotpot_train_v1.1.json\",\n",
    "                     \"hotpot_dev_distractor_v1.json\",\n",
    "                     \"hotpot_dev_fullwiki_v1.json\",\n",
    "                     \"hotpot_test_fullwiki_v1.json\",\n",
    "                     ]\n",
    "        for filename in filenames:\n",
    "            for i, batch in enumerate(dataset.yield_batch(batch_size=2, filename=filename)):\n",
    "                if i > 5:\n",
    "                    break\n",
    "                print(batch)\n",
    "    # Musique\n",
    "    def _test_musique():\n",
    "        print(_test_musique.__name__)\n",
    "        batch_size = 2\n",
    "        dataset = MusiqueDataset(data_dir=data_dir_musique)\n",
    "        types = [\"train\", \"dev\", \"test\"]\n",
    "        categories = [\"ans\", \"full\"]\n",
    "        answerables = [True, False]\n",
    "        for type_ in types:\n",
    "            for category in categories:\n",
    "                if category == \"full\":\n",
    "                    for answerable in answerables:\n",
    "                        print(f\"======== {type_} - {category} - {answerable} ========\")\n",
    "                        for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category, answerable)):\n",
    "                            if i > 5:\n",
    "                                break\n",
    "                            print(batch)\n",
    "                else:\n",
    "                    print(f\"======== {type_} - {category} ========\")\n",
    "                    for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category)):\n",
    "                        if i > 5:\n",
    "                            break\n",
    "                        print(batch)\t\t\t\t\n",
    "\n",
    "    # TriviaQA\n",
    "    def _test_triviaqa():\n",
    "        print(_test_triviaqa.__name__)\n",
    "        batch_size = 2\n",
    "        dataset = TriviaqaDataset(data_dir=data_dir_triviaqa)\n",
    "        types = [\"verified\", \"train\", \"dev\", \"test\"]\n",
    "        categories = [\"web\", \"wikipedia\"]\n",
    "        for type_ in types:\n",
    "            for category in categories:\n",
    "                print(f\"======== {type_} - {category} ========\")\n",
    "                for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category, False)):\n",
    "                    if i > 5:\n",
    "                        break\n",
    "                    print(batch)\t\n",
    "        gc.collect()\n",
    "        for type_ in [\"train\", \"dev\", \"test\"]:\n",
    "            print(f\"======== {type_} - unfiltered ========\")\n",
    "            for i, batch in enumerate(dataset.yield_batch(batch_size, type_, \"web\", True)):\n",
    "                if i > 5:\n",
    "                    break\n",
    "                print(batch)\n",
    "\n",
    "    # Test\t\t\n",
    "    logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "    # _test_race()\n",
    "    # _test_dream()\n",
    "    # _test_squad()\n",
    "    _test_hotpotqa()\n",
    "    # _test_musique()\n",
    "    # _test_triviaqa()\n",
    "    terminate_logger(logger)\n",
    "\n",
    "\n",
    "def test_generate_model_inputs():\n",
    "\n",
    "    def _test_race():\n",
    "        print(_test_race.__name__)\n",
    "        data_dir = DATA_SUMMARY[RaceDataset.dataset_name][\"path\"]\n",
    "        model_path = MODEL_SUMMARY[RobertaLargeFinetunedRace.model_name][\"path\"]\n",
    "        dataset = RaceDataset(data_dir)\n",
    "        model = RobertaLargeFinetunedRace(model_path, device=\"cpu\")\n",
    "\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"], difficulties=[\"high\"])):\n",
    "            model_inputs = RaceDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    def _test_dream():\n",
    "        print(_test_dream.__name__)\n",
    "        data_dir = DATA_SUMMARY[DreamDataset.dataset_name][\"path\"] \n",
    "        model_path = MODEL_SUMMARY[RobertaLargeFinetunedRace.model_name][\"path\"]\n",
    "        dataset = DreamDataset(data_dir)\n",
    "        model = RobertaLargeFinetunedRace(model_path, device=\"cpu\")\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"])):\n",
    "            model_inputs = DreamDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "    _test_race()\n",
    "    # _test_dream()\n",
    "    terminate_logger(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T08:49:20.720959Z",
     "start_time": "2024-09-03T08:49:20.173644Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 16:49:20,175 | base.py | INFO | Check data directory: D:\\resource\\data\\RACE\n",
      "2024-09-03 16:49:20,176 | base.py | INFO | √ ./train/high/\n",
      "2024-09-03 16:49:20,177 | base.py | INFO | √ ./train/middle/\n",
      "2024-09-03 16:49:20,178 | base.py | INFO | √ ./dev/high/\n",
      "2024-09-03 16:49:20,179 | base.py | INFO | √ ./dev/middle/\n",
      "2024-09-03 16:49:20,180 | base.py | INFO | √ ./test/high/\n",
      "2024-09-03 16:49:20,180 | base.py | INFO | √ ./test/middle/\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_test_race\n",
      "{'input_ids': tensor([[[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,    34,   203,   418,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,  3829,     5,  6464,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,  3829,     7,  8933,     5,   850,\n",
      "            227,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,    34,  1085,     7,   109,    53,\n",
      "           3482,     2]],\n",
      "\n",
      "        [[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    49,  1319,     9,  3482,    32,  1341,\n",
      "            430,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,  4157,   349,    97,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,   240,   282,    75,   907,   932,\n",
      "             13,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,   218,    75,    33,    86,    13,\n",
      "             24,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,    34,   203,   418,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,  3829,     5,  6464,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,  3829,     7,  8933,     5,   850,\n",
      "            227,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,    34,  1085,     7,   109,    53,\n",
      "           3482,     2]],\n",
      "\n",
      "        [[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    49,  1319,     9,  3482,    32,  1341,\n",
      "            430,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,  4157,   349,    97,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,   240,   282,    75,   907,   932,\n",
      "             13,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,   218,    75,    33,    86,    13,\n",
      "             24,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,    16,   664,\n",
      "           1437,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,    16, 11640,\n",
      "             12,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,   747, 13585,\n",
      "             39,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,   630,    75,\n",
      "            101,     2]],\n",
      "\n",
      "        [[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,     5,  2792,    21,\n",
      "           1367,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,     5, 20976,  2294,\n",
      "            123,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,    37, 18774,   103,\n",
      "              9,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,    37,   851,    70,\n",
      "              5,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,    16,   664,\n",
      "           1437,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,    16, 11640,\n",
      "             12,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,   747, 13585,\n",
      "             39,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,   630,    75,\n",
      "            101,     2]],\n",
      "\n",
      "        [[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,     5,  2792,    21,\n",
      "           1367,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,     5, 20976,  2294,\n",
      "            123,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,    37, 18774,   103,\n",
      "              9,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,    37,   851,    70,\n",
      "              5,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2]],\n",
      "\n",
      "        [[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,     5,   750,     9,  6845,  4835,    11,  1444,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,   141,  6845,  1059,    10,  1406,  4076,    11,  1444,\n",
      "           1437,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,   141,     5, 24226,   300,     5, 10870,     9,  4835,\n",
      "           6845,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,  1005,     2,     2,   713,  9078,\n",
      "           4412, 14524,  1437,   141,  6845,    12,   958,    21,  2421,  1437,\n",
      "            479,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2]],\n",
      "\n",
      "        [[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,     5,   750,     9,  6845,  4835,    11,  1444,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,   141,  6845,  1059,    10,  1406,  4076,    11,  1444,\n",
      "           1437,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,   141,     5, 24226,   300,     5, 10870,     9,  4835,\n",
      "           6845,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,  1005,     2,     2,   713,  9078,\n",
      "           4412, 14524,  1437,   141,  6845,    12,   958,    21,  2421,  1437,\n",
      "            479,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,  1005,     2,     2, 45866,  1059,\n",
      "             10,  1406,  4076,    11,  1444,  1437,    11, 46111,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11,   411, 33326,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11, 42081, 43169,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11,     5,   628, 42081, 43169,\n",
      "           3220,     2]],\n",
      "\n",
      "        [[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24, 29143,\n",
      "            101,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24, 29143,\n",
      "             55,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24,  1059,\n",
      "             10,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437, 38367,   263,\n",
      "          15206,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,  1005,     2,     2, 45866,  1059,\n",
      "             10,  1406,  4076,    11,  1444,  1437,    11, 46111,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11,   411, 33326,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11, 42081, 43169,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11,     5,   628, 42081, 43169,\n",
      "           3220,     2]],\n",
      "\n",
      "        [[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24, 29143,\n",
      "            101,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24, 29143,\n",
      "             55,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24,  1059,\n",
      "             10,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437, 38367,   263,\n",
      "          15206,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2]],\n",
      "\n",
      "        [[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,   173,   203,  4851,  1437,\n",
      "            479,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,   216,   540,    59,    49,\n",
      "           2148,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437, 10628,    55,    86,    13,\n",
      "           1235,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,  1930,   540,    86,    19,\n",
      "             49,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2]],\n",
      "\n",
      "        [[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,   173,   203,  4851,  1437,\n",
      "            479,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,   216,   540,    59,    49,\n",
      "           2148,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437, 10628,    55,    86,    13,\n",
      "           1235,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,  1930,   540,    86,    19,\n",
      "             49,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 42516,   111,   625, 36237,\n",
      "             12,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 42295,    12,  1246,   111,\n",
      "            625,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116,  3718,    12, 45260,   111,\n",
      "          46781,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 31613,   111, 45260,   111,\n",
      "            625,     2]],\n",
      "\n",
      "        [[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116,    20,  1808,     9,\n",
      "            301,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,  2655,     2,     2,  2264,    74,\n",
      "             28,     5,   275,  1270,    13,     5,  9078,   116, 11714,   358,\n",
      "           2289,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116,    20,  1808,     9,\n",
      "           4835,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116, 41183,   110,   113,\n",
      "          21033,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 42516,   111,   625, 36237,\n",
      "             12,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 42295,    12,  1246,   111,\n",
      "            625,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116,  3718,    12, 45260,   111,\n",
      "          46781,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 31613,   111, 45260,   111,\n",
      "            625,     2]],\n",
      "\n",
      "        [[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116,    20,  1808,     9,\n",
      "            301,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,  2655,     2,     2,  2264,    74,\n",
      "             28,     5,   275,  1270,    13,     5,  9078,   116, 11714,   358,\n",
      "           2289,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116,    20,  1808,     9,\n",
      "           4835,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116, 41183,   110,   113,\n",
      "          21033,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,   252,  6297,\n",
      "             31,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,    20,  5842,\n",
      "           4750,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,  5763,   747,\n",
      "            146,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,   252,    64,\n",
      "             75,     2]],\n",
      "\n",
      "        [[    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,  1701,     5, 20628,     9,   103,\n",
      "            390,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   213,    15, 14221, 16387,    71,\n",
      "            390,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   766, 16387,    71,   604,  1437,\n",
      "            479,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   356,    13,    10,    92,  5448,\n",
      "              7,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,   252,  6297,\n",
      "             31,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,    20,  5842,\n",
      "           4750,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,  5763,   747,\n",
      "            146,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,   252,    64,\n",
      "             75,     2]],\n",
      "\n",
      "        [[    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,  1701,     5, 20628,     9,   103,\n",
      "            390,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   213,    15, 14221, 16387,    71,\n",
      "            390,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   766, 16387,    71,   604,  1437,\n",
      "            479,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   356,    13,    10,    92,  5448,\n",
      "              7,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "# test_yield_batch()\n",
    "test_generate_model_inputs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-adapters-jupyter",
   "language": "python",
   "name": "py39-adapters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
