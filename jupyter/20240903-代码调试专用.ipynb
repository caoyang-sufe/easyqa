{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#测试dataset.yield_batch\" data-toc-modified-id=\"测试dataset.yield_batch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>测试dataset.yield_batch</a></span></li><li><span><a href=\"#测试model.generate_model_inputs\" data-toc-modified-id=\"测试model.generate_model_inputs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>测试model.generate_model_inputs</a></span></li><li><span><a href=\"#测试pipeline.easy_inference_pipeline\" data-toc-modified-id=\"测试pipeline.easy_inference_pipeline-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>测试pipeline.easy_inference_pipeline</a></span></li><li><span><a href=\"#测试modules\" data-toc-modified-id=\"测试modules-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>测试modules</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T03:24:21.584540Z",
     "start_time": "2024-10-17T03:24:16.218229Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py39-adapters\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "E:\\Anaconda3\\envs\\py39-adapters\\lib\\site-packages\\transformers\\utils\\hub.py:127: FutureWarning: Using `PYTORCH_PRETRAINED_BERT_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: D:\\code\\python\\project\\caoyang\\project_019_llm_reasoning\\easyqa\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 切换工作目录\n",
    "if not \"CHDIR_FLAG\" in dir():\n",
    "    os.chdir(\"../\")\n",
    "    CHDIR_FLAG = True\n",
    "else:\n",
    "    assert CHDIR_FLAG is True, CHDIR_FLAG\n",
    "\n",
    "# 导入必要的包\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from configs import ModuleConfig\n",
    "from settings import DATA_DIR, LOG_DIR, MODEL_ROOT, DATA_SUMMARY, MODEL_SUMMARY\n",
    "\n",
    "from src.datasets import RaceDataset, DreamDataset, SquadDataset, HotpotqaDataset, MusiqueDataset, TriviaqaDataset\n",
    "from src.models import RobertaLargeFinetunedRace, LongformerLarge4096AnsweringRace, RobertaBaseSquad2, Chatglm6bInt4, Chatglm26bInt4\n",
    "from src.pipelines import RacePipeline, DreamPipeline, SquadPipeline\n",
    "from src.tools.easy import initialize_logger, terminate_logger, load_args\n",
    "from src.modules import CoMatch\n",
    "\n",
    "from src.tests import comatch_testscript, dcmn_testscript, duma_testscript, hrca_testscript, attention_testscript\n",
    "print(f\"当前工作目录: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试dataset.yield_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:50:28.711653Z",
     "start_time": "2024-10-08T12:48:32.725595Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_yield_batch():\n",
    "    # data_dir = r\"D:\\data\"\t# Lab PC\n",
    "    # data_dir = r\"D:\\resource\\data\"\t# Region Laptop\n",
    "    data_dir = DATA_DIR\t# default\n",
    "    data_dir_race = DATA_SUMMARY[\"RACE\"][\"path\"]\n",
    "    data_dir_dream = DATA_SUMMARY[\"DREAM\"][\"path\"]\n",
    "    data_dir_squad = DATA_SUMMARY[\"SQuAD\"][\"path\"]\n",
    "    data_dir_hotpotqa = DATA_SUMMARY[\"HotpotQA\"][\"path\"]\n",
    "    data_dir_musique = DATA_SUMMARY[\"Musique\"][\"path\"]\n",
    "    data_dir_triviaqa = DATA_SUMMARY[\"TriviaQA\"][\"path\"]\n",
    "\n",
    "    # RACE\n",
    "    def _test_race():\n",
    "        print(_test_race.__name__)\n",
    "        dataset = RaceDataset(data_dir=data_dir_race)\n",
    "        for batch in dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"], difficulties=[\"high\"]):\n",
    "            pass\n",
    "    # DREAM\n",
    "    def _test_dream():\n",
    "        print(_test_dream.__name__)\n",
    "        dataset = DreamDataset(data_dir=data_dir_dream)\n",
    "        for batch in dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"]):\n",
    "            pass\n",
    "    # SQuAD\n",
    "    def _test_squad():\n",
    "        print(_test_squad.__name__)\n",
    "        dataset = SquadDataset(data_dir=data_dir_squad)\n",
    "        versions = [\"1.1\"]\n",
    "        types = [\"train\", \"dev\"]\n",
    "        for version in versions:\n",
    "            for type_ in types:\n",
    "                for i, batch in enumerate(dataset.yield_batch(batch_size=2, type_=type_, version=version)):\n",
    "                    if i > 5:\n",
    "                        break\n",
    "                    print(batch)\n",
    "    # HotpotQA\n",
    "    def _test_hotpotqa():\n",
    "        print(_test_hotpotqa.__name__)\n",
    "        dataset = HotpotqaDataset(data_dir=data_dir_hotpotqa)\n",
    "        filenames = [\"hotpot_train_v1.1.json\",\n",
    "                     \"hotpot_dev_distractor_v1.json\",\n",
    "                     \"hotpot_dev_fullwiki_v1.json\",\n",
    "                     \"hotpot_test_fullwiki_v1.json\",\n",
    "                     ]\n",
    "        for filename in filenames:\n",
    "            for i, batch in enumerate(dataset.yield_batch(batch_size=2, filename=filename)):\n",
    "                if i > 5:\n",
    "                    break\n",
    "                print(batch)\n",
    "    # Musique\n",
    "    def _test_musique():\n",
    "        print(_test_musique.__name__)\n",
    "        batch_size = 2\n",
    "        dataset = MusiqueDataset(data_dir=data_dir_musique)\n",
    "        types = [\"train\", \"dev\", \"test\"]\n",
    "        categories = [\"ans\", \"full\"]\n",
    "        answerables = [True, False]\n",
    "        for type_ in types:\n",
    "            for category in categories:\n",
    "                if category == \"full\":\n",
    "                    for answerable in answerables:\n",
    "                        print(f\"======== {type_} - {category} - {answerable} ========\")\n",
    "                        for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category, answerable)):\n",
    "                            if i > 5:\n",
    "                                break\n",
    "                            print(batch)\n",
    "                else:\n",
    "                    print(f\"======== {type_} - {category} ========\")\n",
    "                    for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category)):\n",
    "                        if i > 5:\n",
    "                            break\n",
    "                        print(batch)\n",
    "\n",
    "    # TriviaQA\n",
    "    def _test_triviaqa():\n",
    "        print(_test_triviaqa.__name__)\n",
    "        n = 1\n",
    "        batch_size = 2\n",
    "        dataset = TriviaqaDataset(data_dir=data_dir_triviaqa)\n",
    "        types = [\"verified\", \"train\", \"dev\", \"test\"]\n",
    "        categories = [\"web\", \"wikipedia\"]\n",
    "        for type_ in types:\n",
    "            for category in categories:\n",
    "                print(f\"======== {type_} - {category} ========\")\n",
    "                for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category, False)):\n",
    "                    if i > n:\n",
    "                        break\n",
    "                    print(batch[0][\"question\"], batch[0][\"answers\"])\n",
    "        gc.collect()\n",
    "        for type_ in types[1:]:\n",
    "            print(f\"======== {type_} - unfiltered ========\")\n",
    "            for i, batch in enumerate(dataset.yield_batch(batch_size, type_, \"web\", True)):\n",
    "                if i > n:\n",
    "                    break\n",
    "                print(batch[0][\"question\"], batch[0][\"answers\"])\n",
    "\n",
    "    # Test\n",
    "    logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "#     _test_race()\n",
    "#     _test_dream()\n",
    "#     _test_squad()\n",
    "#     _test_hotpotqa()\n",
    "#     _test_musique()\n",
    "    _test_triviaqa()\n",
    "    terminate_logger(logger)\n",
    "\n",
    "test_yield_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试model.generate_model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:54:10.485101Z",
     "start_time": "2024-10-08T12:54:08.592621Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_generate_model_inputs():\n",
    "\n",
    "    def _test_race():\n",
    "        print(_test_race.__name__)\n",
    "        data_dir = DATA_SUMMARY[RaceDataset.dataset_name][\"path\"]\n",
    "        model_path = MODEL_SUMMARY[RobertaLargeFinetunedRace.model_name][\"path\"]\n",
    "        # model_path = MODEL_SUMMARY[LongformerLarge4096AnsweringRace.model_name][\"path\"]\n",
    "        dataset = RaceDataset(data_dir)\n",
    "        model = RobertaLargeFinetunedRace(model_path, device=\"cpu\")\n",
    "        # model = LongformerLarge4096AnsweringRace(model_path, device=\"cpu\")\n",
    "\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"], difficulties=[\"high\"])):\n",
    "            model_inputs = RaceDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    def _test_dream():\n",
    "        print(_test_dream.__name__)\n",
    "        data_dir = DATA_SUMMARY[DreamDataset.dataset_name][\"path\"] \n",
    "        model_path = MODEL_SUMMARY[RobertaLargeFinetunedRace.model_name][\"path\"]\n",
    "        dataset = DreamDataset(data_dir)\n",
    "        model = RobertaLargeFinetunedRace(model_path, device=\"cpu\")\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"])):\n",
    "            model_inputs = DreamDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    def _test_squad():\n",
    "        print(_test_squad.__name__)\n",
    "        data_dir = DATA_SUMMARY[SquadDataset.dataset_name][\"path\"]\n",
    "        model_path = MODEL_SUMMARY[RobertaBaseSquad2.model_name][\"path\"]\n",
    "        dataset = SquadDataset(data_dir)\n",
    "        model = RobertaBaseSquad2(model_path, device=\"cpu\")\n",
    "\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, type_=\"dev\", version=\"1.1\")):\n",
    "            model_inputs = SquadDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    def _test_hotpotqa():\n",
    "        print(_test_hotpotqa.__name__)\n",
    "        data_dir = DATA_SUMMARY[HotpotqaDataset.dataset_name][\"path\"]\n",
    "        model_path = MODEL_SUMMARY[Chatglm26bInt4.model_name][\"path\"]\n",
    "        dataset = HotpotqaDataset(data_dir)\n",
    "        model = Chatglm6bInt4(model_path, device=\"cuda\")\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, filename=\"dev_distractor_v1.json\")):\n",
    "            model_inputs = HotpotqaDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=512)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\t\t\n",
    "\n",
    "    logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "    _test_race()\n",
    "    _test_dream()\n",
    "    _test_squad()\n",
    "    _test_hotpotqa()\n",
    "    terminate_logger(logger)\n",
    "\n",
    "test_generate_model_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试pipeline.easy_inference_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference_pipeline():\n",
    "\n",
    "    def _test_race():\n",
    "        race_pipeline = RacePipeline()\n",
    "        pipeline = race_pipeline.easy_inference_pipeline(\n",
    "            dataset_class_name = \"RaceDataset\",\n",
    "            model_class_name = \"RobertaLargeFinetunedRace\",\n",
    "            batch_size = 2,\n",
    "            dataset_kwargs = {\"types\": [\"train\"], \"difficulties\": [\"high\", \"middle\"]},\n",
    "            model_kwargs = {\"max_length\": 512},\n",
    "        )\n",
    "\n",
    "    def _test_squad():\n",
    "        squad_pipeline = SquadPipeline()\n",
    "        pipeline = squad_pipeline.easy_inference_pipeline(\n",
    "            dataset_class_name = \"SquadDataset\",\n",
    "            model_class_name = \"RobertaBaseSquad2\",\n",
    "            batch_size = 2,\n",
    "            dataset_kwargs = {\"type_\": \"train\", \"version\": \"2.0\"},\n",
    "            model_kwargs = {\"max_length\": 512},\n",
    "        )\n",
    "\n",
    "    # logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "    _test_race()\n",
    "    # _test_squad()\n",
    "    # terminate_logger(logger)\n",
    "    \n",
    "    \n",
    "test_inference_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T03:15:57.480400Z",
     "start_time": "2024-10-17T03:15:57.455056Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T03:22:49.579781Z",
     "start_time": "2024-10-17T03:22:49.300951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: -- [-h] [--device DEVICE] [--default_pretrained_model DEFAULT_PRETRAINED_MODEL]\n",
      "          [--default_wordvector DEFAULT_WORDVECTOR] [--default_embedding_size DEFAULT_EMBEDDING_SIZE]\n",
      "          [--word_tokenizer_source WORD_TOKENIZER_SOURCE] [--sentence_tokenizer_source SENTENCE_TOKENIZER_SOURCE]\n",
      "          [--parse_tree_parser_source PARSE_TREE_PARSER_SOURCE] [--dependency_parser_source DEPENDENCY_PARSER_SOURCE]\n",
      "          [--max_article_token MAX_ARTICLE_TOKEN] [--max_article_sentence MAX_ARTICLE_SENTENCE]\n",
      "          [--max_article_sentence_token MAX_ARTICLE_SENTENCE_TOKEN] [--max_question_token MAX_QUESTION_TOKEN]\n",
      "          [--max_option_token MAX_OPTION_TOKEN] [--n_choices N_CHOICES] [--multi_choice MULTI_CHOICE]\n",
      "          [--test_while_train TEST_WHILE_TRAIN] [--comatch_wordvector COMATCH_WORDVECTOR]\n",
      "          [--dcmn_pretrained_model DCMN_PRETRAINED_MODEL] [--duma_pretrained_model DUMA_PRETRAINED_MODEL]\n",
      "          [--hrca_pretrained_model HRCA_PRETRAINED_MODEL] [--use_pretrained_model USE_PRETRAINED_MODEL]\n",
      "          [--load_pretrained_model_in_module LOAD_PRETRAINED_MODEL_IN_MODULE]\n",
      "          [--pretrained_model_device PRETRAINED_MODEL_DEVICE] [--n_epochs N_EPOCHS] [--optimizer OPTIMIZER]\n",
      "          [--learning_rate LEARNING_RATE] [--weight_decay WEIGHT_DECAY] [--lr_step_size LR_STEP_SIZE]\n",
      "          [--lr_multiplier LR_MULTIPLIER] [--save_checkpoint_per_epoch SAVE_CHECKPOINT_PER_EPOCH]\n",
      "          [--comatch_embedding_size COMATCH_EMBEDDING_SIZE] [--comatch_bilstm_hidden_size COMATCH_BILSTM_HIDDEN_SIZE]\n",
      "          [--comatch_bilstm_num_layers COMATCH_BILSTM_NUM_LAYERS]\n",
      "          [--comatch_bilstm_bidirectional COMATCH_BILSTM_BIDIRECTIONAL]\n",
      "          [--comatch_bilstm_dropout COMATCH_BILSTM_DROPOUT] [--dcmn_scoring_method DCMN_SCORING_METHOD]\n",
      "          [--dcmn_num_passage_sentence_selection DCMN_NUM_PASSAGE_SENTENCE_SELECTION]\n",
      "          [--dcmn_encoding_size DCMN_ENCODING_SIZE] [--duma_num_layers DUMA_NUM_LAYERS]\n",
      "          [--duma_encoding_size DUMA_ENCODING_SIZE] [--duma_fuse_method DUMA_FUSE_METHOD]\n",
      "          [--duma_mha_num_heads DUMA_MHA_NUM_HEADS] [--duma_mha_dropout_rate DUMA_MHA_DROPOUT_RATE]\n",
      "          [--hrca_num_layers HRCA_NUM_LAYERS] [--hrca_encoding_size HRCA_ENCODING_SIZE]\n",
      "          [--hrca_fuse_method HRCA_FUSE_METHOD] [--hrca_mha_num_heads HRCA_MHA_NUM_HEADS]\n",
      "          [--hrca_mha_dropout_rate HRCA_MHA_DROPOUT_RATE] [--hrca_plus HRCA_PLUS]\n",
      "--: error: unrecognized arguments: -f C:\\Users\\caoyang\\AppData\\Roaming\\jupyter\\runtime\\kernel-699b3f38-801f-482f-a298-096beef5addd.json\n",
      "WARNING:root:Key train_batch_size not in arguments but you want to change its value to 8!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------\n",
      "|               Param Name               |          Param Size          |  Param #  |\n",
      "-------------------------------------------------------------------------------------\n",
      "|     Encoder_P.lstm.weight_ih_l0        |   torch.Size([128, 300])     |  38400    |\n",
      "|     Encoder_P.lstm.weight_hh_l0        |   torch.Size([128, 32])      |  4096     |\n",
      "|      Encoder_P.lstm.bias_ih_l0         |     torch.Size([128])        |   128     |\n",
      "|      Encoder_P.lstm.bias_hh_l0         |     torch.Size([128])        |   128     |\n",
      "| Encoder_P.lstm.weight_ih_l0_reverse    |   torch.Size([128, 300])     |  38400    |\n",
      "| Encoder_P.lstm.weight_hh_l0_reverse    |   torch.Size([128, 32])      |  4096     |\n",
      "|  Encoder_P.lstm.bias_ih_l0_reverse     |     torch.Size([128])        |   128     |\n",
      "|  Encoder_P.lstm.bias_hh_l0_reverse     |     torch.Size([128])        |   128     |\n",
      "|     Encoder_P.lstm.weight_ih_l1        |   torch.Size([128, 64])      |  8192     |\n",
      "|     Encoder_P.lstm.weight_hh_l1        |   torch.Size([128, 32])      |  4096     |\n",
      "|      Encoder_P.lstm.bias_ih_l1         |     torch.Size([128])        |   128     |\n",
      "|      Encoder_P.lstm.bias_hh_l1         |     torch.Size([128])        |   128     |\n",
      "| Encoder_P.lstm.weight_ih_l1_reverse    |   torch.Size([128, 64])      |  8192     |\n",
      "| Encoder_P.lstm.weight_hh_l1_reverse    |   torch.Size([128, 32])      |  4096     |\n",
      "|  Encoder_P.lstm.bias_ih_l1_reverse     |     torch.Size([128])        |   128     |\n",
      "|  Encoder_P.lstm.bias_hh_l1_reverse     |     torch.Size([128])        |   128     |\n",
      "|     Encoder_Q.lstm.weight_ih_l0        |   torch.Size([128, 300])     |  38400    |\n",
      "|     Encoder_Q.lstm.weight_hh_l0        |   torch.Size([128, 32])      |  4096     |\n",
      "|      Encoder_Q.lstm.bias_ih_l0         |     torch.Size([128])        |   128     |\n",
      "|      Encoder_Q.lstm.bias_hh_l0         |     torch.Size([128])        |   128     |\n",
      "| Encoder_Q.lstm.weight_ih_l0_reverse    |   torch.Size([128, 300])     |  38400    |\n",
      "| Encoder_Q.lstm.weight_hh_l0_reverse    |   torch.Size([128, 32])      |  4096     |\n",
      "|  Encoder_Q.lstm.bias_ih_l0_reverse     |     torch.Size([128])        |   128     |\n",
      "|  Encoder_Q.lstm.bias_hh_l0_reverse     |     torch.Size([128])        |   128     |\n",
      "|     Encoder_Q.lstm.weight_ih_l1        |   torch.Size([128, 64])      |  8192     |\n",
      "|     Encoder_Q.lstm.weight_hh_l1        |   torch.Size([128, 32])      |  4096     |\n",
      "|      Encoder_Q.lstm.bias_ih_l1         |     torch.Size([128])        |   128     |\n",
      "|      Encoder_Q.lstm.bias_hh_l1         |     torch.Size([128])        |   128     |\n",
      "| Encoder_Q.lstm.weight_ih_l1_reverse    |   torch.Size([128, 64])      |  8192     |\n",
      "| Encoder_Q.lstm.weight_hh_l1_reverse    |   torch.Size([128, 32])      |  4096     |\n",
      "|  Encoder_Q.lstm.bias_ih_l1_reverse     |     torch.Size([128])        |   128     |\n",
      "|  Encoder_Q.lstm.bias_hh_l1_reverse     |     torch.Size([128])        |   128     |\n",
      "|     Encoder_A.lstm.weight_ih_l0        |   torch.Size([128, 300])     |  38400    |\n",
      "|     Encoder_A.lstm.weight_hh_l0        |   torch.Size([128, 32])      |  4096     |\n",
      "|      Encoder_A.lstm.bias_ih_l0         |     torch.Size([128])        |   128     |\n",
      "|      Encoder_A.lstm.bias_hh_l0         |     torch.Size([128])        |   128     |\n",
      "| Encoder_A.lstm.weight_ih_l0_reverse    |   torch.Size([128, 300])     |  38400    |\n",
      "| Encoder_A.lstm.weight_hh_l0_reverse    |   torch.Size([128, 32])      |  4096     |\n",
      "|  Encoder_A.lstm.bias_ih_l0_reverse     |     torch.Size([128])        |   128     |\n",
      "|  Encoder_A.lstm.bias_hh_l0_reverse     |     torch.Size([128])        |   128     |\n",
      "|     Encoder_A.lstm.weight_ih_l1        |   torch.Size([128, 64])      |  8192     |\n",
      "|     Encoder_A.lstm.weight_hh_l1        |   torch.Size([128, 32])      |  4096     |\n",
      "|      Encoder_A.lstm.bias_ih_l1         |     torch.Size([128])        |   128     |\n",
      "|      Encoder_A.lstm.bias_hh_l1         |     torch.Size([128])        |   128     |\n",
      "| Encoder_A.lstm.weight_ih_l1_reverse    |   torch.Size([128, 64])      |  8192     |\n",
      "| Encoder_A.lstm.weight_hh_l1_reverse    |   torch.Size([128, 32])      |  4096     |\n",
      "|  Encoder_A.lstm.bias_ih_l1_reverse     |     torch.Size([128])        |   128     |\n",
      "|  Encoder_A.lstm.bias_hh_l1_reverse     |     torch.Size([128])        |   128     |\n",
      "|        Encoder_C.weight_ih_l0          |   torch.Size([128, 128])     |  16384    |\n",
      "|        Encoder_C.weight_hh_l0          |   torch.Size([128, 32])      |  4096     |\n",
      "|         Encoder_C.bias_ih_l0           |     torch.Size([128])        |   128     |\n",
      "|         Encoder_C.bias_hh_l0           |     torch.Size([128])        |   128     |\n",
      "|    Encoder_C.weight_ih_l0_reverse      |   torch.Size([128, 128])     |  16384    |\n",
      "|    Encoder_C.weight_hh_l0_reverse      |   torch.Size([128, 32])      |  4096     |\n",
      "|     Encoder_C.bias_ih_l0_reverse       |     torch.Size([128])        |   128     |\n",
      "|     Encoder_C.bias_hh_l0_reverse       |     torch.Size([128])        |   128     |\n",
      "|        Encoder_C.weight_ih_l1          |   torch.Size([128, 64])      |  8192     |\n",
      "|        Encoder_C.weight_hh_l1          |   torch.Size([128, 32])      |  4096     |\n",
      "|         Encoder_C.bias_ih_l1           |     torch.Size([128])        |   128     |\n",
      "|         Encoder_C.bias_hh_l1           |     torch.Size([128])        |   128     |\n",
      "|    Encoder_C.weight_ih_l1_reverse      |   torch.Size([128, 64])      |  8192     |\n",
      "|    Encoder_C.weight_hh_l1_reverse      |   torch.Size([128, 32])      |  4096     |\n",
      "|     Encoder_C.bias_ih_l1_reverse       |     torch.Size([128])        |   128     |\n",
      "|     Encoder_C.bias_hh_l1_reverse       |     torch.Size([128])        |   128     |\n",
      "|       Encoder_H_s.weight_ih_l0         |   torch.Size([128, 64])      |  8192     |\n",
      "|       Encoder_H_s.weight_hh_l0         |   torch.Size([128, 32])      |  4096     |\n",
      "|        Encoder_H_s.bias_ih_l0          |     torch.Size([128])        |   128     |\n",
      "|        Encoder_H_s.bias_hh_l0          |     torch.Size([128])        |   128     |\n",
      "|   Encoder_H_s.weight_ih_l0_reverse     |   torch.Size([128, 64])      |  8192     |\n",
      "|   Encoder_H_s.weight_hh_l0_reverse     |   torch.Size([128, 32])      |  4096     |\n",
      "|    Encoder_H_s.bias_ih_l0_reverse      |     torch.Size([128])        |   128     |\n",
      "|    Encoder_H_s.bias_hh_l0_reverse      |     torch.Size([128])        |   128     |\n",
      "|       Encoder_H_s.weight_ih_l1         |   torch.Size([128, 64])      |  8192     |\n",
      "|       Encoder_H_s.weight_hh_l1         |   torch.Size([128, 32])      |  4096     |\n",
      "|        Encoder_H_s.bias_ih_l1          |     torch.Size([128])        |   128     |\n",
      "|        Encoder_H_s.bias_hh_l1          |     torch.Size([128])        |   128     |\n",
      "|   Encoder_H_s.weight_ih_l1_reverse     |   torch.Size([128, 64])      |  8192     |\n",
      "|   Encoder_H_s.weight_hh_l1_reverse     |   torch.Size([128, 32])      |  4096     |\n",
      "|    Encoder_H_s.bias_ih_l1_reverse      |     torch.Size([128])        |   128     |\n",
      "|    Encoder_H_s.bias_hh_l1_reverse      |     torch.Size([128])        |   128     |\n",
      "|              W_g.weight                |    torch.Size([64, 64])      |  4096     |\n",
      "|               W_g.bias                 |      torch.Size([64])        |   64      |\n",
      "|              W_m.weight                |   torch.Size([64, 128])      |  8192     |\n",
      "|               W_m.bias                 |      torch.Size([64])        |   64      |\n",
      "|               w.weight                 |    torch.Size([1, 64])       |   64      |\n",
      "-------------------------------------------------------------------------------------\n",
      "The total number of parameters: 460992\n",
      "The parameters of Model CoMatchTest: 0.461M\n",
      "-------------------------------------------------------------------------------------\n",
      "======== Co-Matching Test Report ========\n",
      "Output of CoMatch:\n",
      "tensor([[-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Output of VerbosedCoMatch:\n",
      "tensor([[-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863],\n",
      "        [-1.3863, -1.3863, -1.3863, -1.3863]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Error:\t0.0\n",
      "Result:\tSuccess\n",
      "=========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comatch_testscript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T03:22:51.854460Z",
     "start_time": "2024-10-17T03:22:49.752063Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: -- [-h] [--device DEVICE] [--default_pretrained_model DEFAULT_PRETRAINED_MODEL]\n",
      "          [--default_wordvector DEFAULT_WORDVECTOR] [--default_embedding_size DEFAULT_EMBEDDING_SIZE]\n",
      "          [--word_tokenizer_source WORD_TOKENIZER_SOURCE] [--sentence_tokenizer_source SENTENCE_TOKENIZER_SOURCE]\n",
      "          [--parse_tree_parser_source PARSE_TREE_PARSER_SOURCE] [--dependency_parser_source DEPENDENCY_PARSER_SOURCE]\n",
      "          [--max_article_token MAX_ARTICLE_TOKEN] [--max_article_sentence MAX_ARTICLE_SENTENCE]\n",
      "          [--max_article_sentence_token MAX_ARTICLE_SENTENCE_TOKEN] [--max_question_token MAX_QUESTION_TOKEN]\n",
      "          [--max_option_token MAX_OPTION_TOKEN] [--n_choices N_CHOICES] [--multi_choice MULTI_CHOICE]\n",
      "          [--test_while_train TEST_WHILE_TRAIN] [--comatch_wordvector COMATCH_WORDVECTOR]\n",
      "          [--dcmn_pretrained_model DCMN_PRETRAINED_MODEL] [--duma_pretrained_model DUMA_PRETRAINED_MODEL]\n",
      "          [--hrca_pretrained_model HRCA_PRETRAINED_MODEL] [--use_pretrained_model USE_PRETRAINED_MODEL]\n",
      "          [--load_pretrained_model_in_module LOAD_PRETRAINED_MODEL_IN_MODULE]\n",
      "          [--pretrained_model_device PRETRAINED_MODEL_DEVICE] [--n_epochs N_EPOCHS] [--optimizer OPTIMIZER]\n",
      "          [--learning_rate LEARNING_RATE] [--weight_decay WEIGHT_DECAY] [--lr_step_size LR_STEP_SIZE]\n",
      "          [--lr_multiplier LR_MULTIPLIER] [--save_checkpoint_per_epoch SAVE_CHECKPOINT_PER_EPOCH]\n",
      "          [--comatch_embedding_size COMATCH_EMBEDDING_SIZE] [--comatch_bilstm_hidden_size COMATCH_BILSTM_HIDDEN_SIZE]\n",
      "          [--comatch_bilstm_num_layers COMATCH_BILSTM_NUM_LAYERS]\n",
      "          [--comatch_bilstm_bidirectional COMATCH_BILSTM_BIDIRECTIONAL]\n",
      "          [--comatch_bilstm_dropout COMATCH_BILSTM_DROPOUT] [--dcmn_scoring_method DCMN_SCORING_METHOD]\n",
      "          [--dcmn_num_passage_sentence_selection DCMN_NUM_PASSAGE_SENTENCE_SELECTION]\n",
      "          [--dcmn_encoding_size DCMN_ENCODING_SIZE] [--duma_num_layers DUMA_NUM_LAYERS]\n",
      "          [--duma_encoding_size DUMA_ENCODING_SIZE] [--duma_fuse_method DUMA_FUSE_METHOD]\n",
      "          [--duma_mha_num_heads DUMA_MHA_NUM_HEADS] [--duma_mha_dropout_rate DUMA_MHA_DROPOUT_RATE]\n",
      "          [--hrca_num_layers HRCA_NUM_LAYERS] [--hrca_encoding_size HRCA_ENCODING_SIZE]\n",
      "          [--hrca_fuse_method HRCA_FUSE_METHOD] [--hrca_mha_num_heads HRCA_MHA_NUM_HEADS]\n",
      "          [--hrca_mha_dropout_rate HRCA_MHA_DROPOUT_RATE] [--hrca_plus HRCA_PLUS]\n",
      "--: error: unrecognized arguments: -f C:\\Users\\caoyang\\AppData\\Roaming\\jupyter\\runtime\\kernel-699b3f38-801f-482f-a298-096beef5addd.json\n",
      "WARNING:root:Key train_batch_size not in arguments but you want to change its value to 8!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                             Param Name                                             |          Param Size          |  Param #  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                            W_5.weight                                              |   torch.Size([768, 768])     | 589824    |\n",
      "|                                            W_6.weight                                              |  torch.Size([768, 2304])     | 1769472   |\n",
      "|                                            W_7.weight                                              |   torch.Size([768, 768])     | 589824    |\n",
      "|                                            W_8.weight                                              |   torch.Size([768, 768])     | 589824    |\n",
      "|                                             W_8.bias                                               |     torch.Size([768])        |   768     |\n",
      "|                                            W_9.weight                                              |   torch.Size([768, 768])     | 589824    |\n",
      "|                                           W_10.weight                                              |   torch.Size([768, 768])     | 589824    |\n",
      "|                                           W_11.weight                                              |   torch.Size([768, 768])     | 589824    |\n",
      "|                                           W_12.weight                                              |   torch.Size([768, 768])     | 589824    |\n",
      "|                                           W_13.weight                                              |   torch.Size([768, 768])     | 589824    |\n",
      "|                                           W_14.weight                                              |   torch.Size([768, 768])     | 589824    |\n",
      "|                                            W_14.bias                                               |     torch.Size([768])        |   768     |\n",
      "|                                             V.weight                                               |   torch.Size([1, 2304])      |  2304     |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "The total number of parameters: 7081728\n",
      "The parameters of Model DCMN: 7.0817M\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dcmn_testscript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T03:22:59.049999Z",
     "start_time": "2024-10-17T03:22:52.028424Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: -- [-h] [--device DEVICE] [--default_pretrained_model DEFAULT_PRETRAINED_MODEL]\n",
      "          [--default_wordvector DEFAULT_WORDVECTOR] [--default_embedding_size DEFAULT_EMBEDDING_SIZE]\n",
      "          [--word_tokenizer_source WORD_TOKENIZER_SOURCE] [--sentence_tokenizer_source SENTENCE_TOKENIZER_SOURCE]\n",
      "          [--parse_tree_parser_source PARSE_TREE_PARSER_SOURCE] [--dependency_parser_source DEPENDENCY_PARSER_SOURCE]\n",
      "          [--max_article_token MAX_ARTICLE_TOKEN] [--max_article_sentence MAX_ARTICLE_SENTENCE]\n",
      "          [--max_article_sentence_token MAX_ARTICLE_SENTENCE_TOKEN] [--max_question_token MAX_QUESTION_TOKEN]\n",
      "          [--max_option_token MAX_OPTION_TOKEN] [--n_choices N_CHOICES] [--multi_choice MULTI_CHOICE]\n",
      "          [--test_while_train TEST_WHILE_TRAIN] [--comatch_wordvector COMATCH_WORDVECTOR]\n",
      "          [--dcmn_pretrained_model DCMN_PRETRAINED_MODEL] [--duma_pretrained_model DUMA_PRETRAINED_MODEL]\n",
      "          [--hrca_pretrained_model HRCA_PRETRAINED_MODEL] [--use_pretrained_model USE_PRETRAINED_MODEL]\n",
      "          [--load_pretrained_model_in_module LOAD_PRETRAINED_MODEL_IN_MODULE]\n",
      "          [--pretrained_model_device PRETRAINED_MODEL_DEVICE] [--n_epochs N_EPOCHS] [--optimizer OPTIMIZER]\n",
      "          [--learning_rate LEARNING_RATE] [--weight_decay WEIGHT_DECAY] [--lr_step_size LR_STEP_SIZE]\n",
      "          [--lr_multiplier LR_MULTIPLIER] [--save_checkpoint_per_epoch SAVE_CHECKPOINT_PER_EPOCH]\n",
      "          [--comatch_embedding_size COMATCH_EMBEDDING_SIZE] [--comatch_bilstm_hidden_size COMATCH_BILSTM_HIDDEN_SIZE]\n",
      "          [--comatch_bilstm_num_layers COMATCH_BILSTM_NUM_LAYERS]\n",
      "          [--comatch_bilstm_bidirectional COMATCH_BILSTM_BIDIRECTIONAL]\n",
      "          [--comatch_bilstm_dropout COMATCH_BILSTM_DROPOUT] [--dcmn_scoring_method DCMN_SCORING_METHOD]\n",
      "          [--dcmn_num_passage_sentence_selection DCMN_NUM_PASSAGE_SENTENCE_SELECTION]\n",
      "          [--dcmn_encoding_size DCMN_ENCODING_SIZE] [--duma_num_layers DUMA_NUM_LAYERS]\n",
      "          [--duma_encoding_size DUMA_ENCODING_SIZE] [--duma_fuse_method DUMA_FUSE_METHOD]\n",
      "          [--duma_mha_num_heads DUMA_MHA_NUM_HEADS] [--duma_mha_dropout_rate DUMA_MHA_DROPOUT_RATE]\n",
      "          [--hrca_num_layers HRCA_NUM_LAYERS] [--hrca_encoding_size HRCA_ENCODING_SIZE]\n",
      "          [--hrca_fuse_method HRCA_FUSE_METHOD] [--hrca_mha_num_heads HRCA_MHA_NUM_HEADS]\n",
      "          [--hrca_mha_dropout_rate HRCA_MHA_DROPOUT_RATE] [--hrca_plus HRCA_PLUS]\n",
      "--: error: unrecognized arguments: -f C:\\Users\\caoyang\\AppData\\Roaming\\jupyter\\runtime\\kernel-699b3f38-801f-482f-a298-096beef5addd.json\n",
      "WARNING:root:Key train_batch_size not in arguments but you want to change its value to 8!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 4])\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                             Param Name                                             |          Param Size          |  Param #  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                 multi_head_attention.W_Q.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_Q.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_K.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_K.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_V.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_V.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_O.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_O.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                       fuse_linear_x.weight                                         |   torch.Size([768, 768])     | 589824    |\n",
      "|                                        fuse_linear_x.bias                                          |     torch.Size([768])        |   768     |\n",
      "|                                       fuse_linear_y.weight                                         |   torch.Size([768, 768])     | 589824    |\n",
      "|                                        fuse_linear_y.bias                                          |     torch.Size([768])        |   768     |\n",
      "|                                             W.weight                                               |    torch.Size([1, 768])      |   768     |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "The total number of parameters: 3544320\n",
      "The parameters of Model DUMA: 3.5443M\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 40, 768])\n",
      "torch.Size([8, 4])\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                             Param Name                                             |          Param Size          |  Param #  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                 multi_head_attention.W_Q.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_Q.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_K.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_K.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_V.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_V.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_O.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_O.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                       fuse_linear_x.weight                                         |   torch.Size([768, 768])     | 589824    |\n",
      "|                                        fuse_linear_x.bias                                          |     torch.Size([768])        |   768     |\n",
      "|                                       fuse_linear_y.weight                                         |   torch.Size([768, 768])     | 589824    |\n",
      "|                                        fuse_linear_y.bias                                          |     torch.Size([768])        |   768     |\n",
      "|                                             W.weight                                               |    torch.Size([1, 768])      |   768     |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "The total number of parameters: 3544320\n",
      "The parameters of Model DUMAv1: 3.5443M\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "duma_testscript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T03:24:30.792947Z",
     "start_time": "2024-10-17T03:24:21.787065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: -- [-h] [--device DEVICE] [--default_pretrained_model DEFAULT_PRETRAINED_MODEL]\n",
      "          [--default_wordvector DEFAULT_WORDVECTOR] [--default_embedding_size DEFAULT_EMBEDDING_SIZE]\n",
      "          [--word_tokenizer_source WORD_TOKENIZER_SOURCE] [--sentence_tokenizer_source SENTENCE_TOKENIZER_SOURCE]\n",
      "          [--parse_tree_parser_source PARSE_TREE_PARSER_SOURCE] [--dependency_parser_source DEPENDENCY_PARSER_SOURCE]\n",
      "          [--max_article_token MAX_ARTICLE_TOKEN] [--max_article_sentence MAX_ARTICLE_SENTENCE]\n",
      "          [--max_article_sentence_token MAX_ARTICLE_SENTENCE_TOKEN] [--max_question_token MAX_QUESTION_TOKEN]\n",
      "          [--max_option_token MAX_OPTION_TOKEN] [--n_choices N_CHOICES] [--multi_choice MULTI_CHOICE]\n",
      "          [--test_while_train TEST_WHILE_TRAIN] [--comatch_wordvector COMATCH_WORDVECTOR]\n",
      "          [--dcmn_pretrained_model DCMN_PRETRAINED_MODEL] [--duma_pretrained_model DUMA_PRETRAINED_MODEL]\n",
      "          [--hrca_pretrained_model HRCA_PRETRAINED_MODEL] [--use_pretrained_model USE_PRETRAINED_MODEL]\n",
      "          [--load_pretrained_model_in_module LOAD_PRETRAINED_MODEL_IN_MODULE]\n",
      "          [--pretrained_model_device PRETRAINED_MODEL_DEVICE] [--n_epochs N_EPOCHS] [--optimizer OPTIMIZER]\n",
      "          [--learning_rate LEARNING_RATE] [--weight_decay WEIGHT_DECAY] [--lr_step_size LR_STEP_SIZE]\n",
      "          [--lr_multiplier LR_MULTIPLIER] [--save_checkpoint_per_epoch SAVE_CHECKPOINT_PER_EPOCH]\n",
      "          [--comatch_embedding_size COMATCH_EMBEDDING_SIZE] [--comatch_bilstm_hidden_size COMATCH_BILSTM_HIDDEN_SIZE]\n",
      "          [--comatch_bilstm_num_layers COMATCH_BILSTM_NUM_LAYERS]\n",
      "          [--comatch_bilstm_bidirectional COMATCH_BILSTM_BIDIRECTIONAL]\n",
      "          [--comatch_bilstm_dropout COMATCH_BILSTM_DROPOUT] [--dcmn_scoring_method DCMN_SCORING_METHOD]\n",
      "          [--dcmn_num_passage_sentence_selection DCMN_NUM_PASSAGE_SENTENCE_SELECTION]\n",
      "          [--dcmn_encoding_size DCMN_ENCODING_SIZE] [--duma_num_layers DUMA_NUM_LAYERS]\n",
      "          [--duma_encoding_size DUMA_ENCODING_SIZE] [--duma_fuse_method DUMA_FUSE_METHOD]\n",
      "          [--duma_mha_num_heads DUMA_MHA_NUM_HEADS] [--duma_mha_dropout_rate DUMA_MHA_DROPOUT_RATE]\n",
      "          [--hrca_num_layers HRCA_NUM_LAYERS] [--hrca_encoding_size HRCA_ENCODING_SIZE]\n",
      "          [--hrca_fuse_method HRCA_FUSE_METHOD] [--hrca_mha_num_heads HRCA_MHA_NUM_HEADS]\n",
      "          [--hrca_mha_dropout_rate HRCA_MHA_DROPOUT_RATE] [--hrca_plus HRCA_PLUS]\n",
      "--: error: unrecognized arguments: -f C:\\Users\\caoyang\\AppData\\Roaming\\jupyter\\runtime\\kernel-699b3f38-801f-482f-a298-096beef5addd.json\n",
      "WARNING:root:Key train_batch_size not in arguments but you want to change its value to 8!\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 4])\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                             Param Name                                             |          Param Size          |  Param #  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                 multi_head_attention.W_Q.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_Q.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_K.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_K.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_V.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_V.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_O.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_O.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                       fuse_linear_x.weight                                         |   torch.Size([768, 768])     | 589824    |\n",
      "|                                        fuse_linear_x.bias                                          |     torch.Size([768])        |   768     |\n",
      "|                                       fuse_linear_y.weight                                         |   torch.Size([768, 768])     | 589824    |\n",
      "|                                        fuse_linear_y.bias                                          |     torch.Size([768])        |   768     |\n",
      "|                                       fuse_linear_z.weight                                         |   torch.Size([768, 768])     | 589824    |\n",
      "|                                        fuse_linear_z.bias                                          |     torch.Size([768])        |   768     |\n",
      "|                                             W.weight                                               |   torch.Size([1, 2304])      |  2304     |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "The total number of parameters: 4136448\n",
      "The parameters of Model HRCA: 4.1364M\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 24, 768])\n",
      "torch.Size([8, 16, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 128, 768])\n",
      "torch.Size([8, 4])\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                             Param Name                                             |          Param Size          |  Param #  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                 multi_head_attention.W_Q.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_Q.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_K.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_K.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_V.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_V.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                 multi_head_attention.W_O.weight                                    |   torch.Size([768, 768])     | 589824    |\n",
      "|                                  multi_head_attention.W_O.bias                                     |     torch.Size([768])        |   768     |\n",
      "|                                       fuse_linear_x.weight                                         |   torch.Size([768, 768])     | 589824    |\n",
      "|                                        fuse_linear_x.bias                                          |     torch.Size([768])        |   768     |\n",
      "|                                       fuse_linear_y.weight                                         |   torch.Size([768, 768])     | 589824    |\n",
      "|                                        fuse_linear_y.bias                                          |     torch.Size([768])        |   768     |\n",
      "|                                       fuse_linear_z.weight                                         |   torch.Size([768, 768])     | 589824    |\n",
      "|                                        fuse_linear_z.bias                                          |     torch.Size([768])        |   768     |\n",
      "|                                             W.weight                                               |   torch.Size([1, 2304])      |  2304     |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "The total number of parameters: 4136448\n",
      "The parameters of Model HRCAv1: 4.1364M\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "hrca_testscript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-adapters-jupyter",
   "language": "python",
   "name": "py39-adapters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
