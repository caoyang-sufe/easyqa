{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#测试dataset.yield_batch\" data-toc-modified-id=\"测试dataset.yield_batch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>测试dataset.yield_batch</a></span></li><li><span><a href=\"#测试model.generate_model_inputs\" data-toc-modified-id=\"测试model.generate_model_inputs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>测试model.generate_model_inputs</a></span></li><li><span><a href=\"#测试pipeline.easy_inference_pipeline\" data-toc-modified-id=\"测试pipeline.easy_inference_pipeline-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>测试pipeline.easy_inference_pipeline</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:54:05.348134Z",
     "start_time": "2024-10-08T12:54:04.759260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: D:\\code\\python\\project\\caoyang\\project_019_llm_reasoning\\easyqa\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 切换工作目录\n",
    "if not \"CHDIR_FLAG\" in dir():\n",
    "    os.chdir(\"../\")\n",
    "    CHDIR_FLAG = True\n",
    "else:\n",
    "    assert CHDIR_FLAG is True, CHDIR_FLAG\n",
    "\n",
    "# 导入必要的包\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from settings import DATA_DIR, LOG_DIR, MODEL_ROOT, DATA_SUMMARY, MODEL_SUMMARY\n",
    "\n",
    "from src.datasets import RaceDataset, DreamDataset, SquadDataset, HotpotqaDataset, MusiqueDataset, TriviaqaDataset\n",
    "from src.models import RobertaLargeFinetunedRace, LongformerLarge4096AnsweringRace, RobertaBaseSquad2, Chatglm6bInt4, Chatglm26bInt4\n",
    "from src.pipelines import RacePipeline, DreamPipeline, SquadPipeline\n",
    "from src.tools.easy import initialize_logger, terminate_logger\n",
    "\n",
    "print(f\"当前工作目录: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试dataset.yield_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:50:28.711653Z",
     "start_time": "2024-10-08T12:48:32.725595Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_yield_batch():\n",
    "    # data_dir = r\"D:\\data\"\t# Lab PC\n",
    "    # data_dir = r\"D:\\resource\\data\"\t# Region Laptop\n",
    "    data_dir = DATA_DIR\t# default\n",
    "    data_dir_race = DATA_SUMMARY[\"RACE\"][\"path\"]\n",
    "    data_dir_dream = DATA_SUMMARY[\"DREAM\"][\"path\"]\n",
    "    data_dir_squad = DATA_SUMMARY[\"SQuAD\"][\"path\"]\n",
    "    data_dir_hotpotqa = DATA_SUMMARY[\"HotpotQA\"][\"path\"]\n",
    "    data_dir_musique = DATA_SUMMARY[\"Musique\"][\"path\"]\n",
    "    data_dir_triviaqa = DATA_SUMMARY[\"TriviaQA\"][\"path\"]\n",
    "\n",
    "    # RACE\n",
    "    def _test_race():\n",
    "        print(_test_race.__name__)\n",
    "        dataset = RaceDataset(data_dir=data_dir_race)\n",
    "        for batch in dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"], difficulties=[\"high\"]):\n",
    "            pass\n",
    "    # DREAM\n",
    "    def _test_dream():\n",
    "        print(_test_dream.__name__)\n",
    "        dataset = DreamDataset(data_dir=data_dir_dream)\n",
    "        for batch in dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"]):\n",
    "            pass\n",
    "    # SQuAD\n",
    "    def _test_squad():\n",
    "        print(_test_squad.__name__)\n",
    "        dataset = SquadDataset(data_dir=data_dir_squad)\n",
    "        versions = [\"1.1\"]\n",
    "        types = [\"train\", \"dev\"]\n",
    "        for version in versions:\n",
    "            for type_ in types:\n",
    "                for i, batch in enumerate(dataset.yield_batch(batch_size=2, type_=type_, version=version)):\n",
    "                    if i > 5:\n",
    "                        break\n",
    "                    print(batch)\n",
    "    # HotpotQA\n",
    "    def _test_hotpotqa():\n",
    "        print(_test_hotpotqa.__name__)\n",
    "        dataset = HotpotqaDataset(data_dir=data_dir_hotpotqa)\n",
    "        filenames = [\"hotpot_train_v1.1.json\",\n",
    "                     \"hotpot_dev_distractor_v1.json\",\n",
    "                     \"hotpot_dev_fullwiki_v1.json\",\n",
    "                     \"hotpot_test_fullwiki_v1.json\",\n",
    "                     ]\n",
    "        for filename in filenames:\n",
    "            for i, batch in enumerate(dataset.yield_batch(batch_size=2, filename=filename)):\n",
    "                if i > 5:\n",
    "                    break\n",
    "                print(batch)\n",
    "    # Musique\n",
    "    def _test_musique():\n",
    "        print(_test_musique.__name__)\n",
    "        batch_size = 2\n",
    "        dataset = MusiqueDataset(data_dir=data_dir_musique)\n",
    "        types = [\"train\", \"dev\", \"test\"]\n",
    "        categories = [\"ans\", \"full\"]\n",
    "        answerables = [True, False]\n",
    "        for type_ in types:\n",
    "            for category in categories:\n",
    "                if category == \"full\":\n",
    "                    for answerable in answerables:\n",
    "                        print(f\"======== {type_} - {category} - {answerable} ========\")\n",
    "                        for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category, answerable)):\n",
    "                            if i > 5:\n",
    "                                break\n",
    "                            print(batch)\n",
    "                else:\n",
    "                    print(f\"======== {type_} - {category} ========\")\n",
    "                    for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category)):\n",
    "                        if i > 5:\n",
    "                            break\n",
    "                        print(batch)\n",
    "\n",
    "    # TriviaQA\n",
    "    def _test_triviaqa():\n",
    "        print(_test_triviaqa.__name__)\n",
    "        n = 1\n",
    "        batch_size = 2\n",
    "        dataset = TriviaqaDataset(data_dir=data_dir_triviaqa)\n",
    "        types = [\"verified\", \"train\", \"dev\", \"test\"]\n",
    "        categories = [\"web\", \"wikipedia\"]\n",
    "        for type_ in types:\n",
    "            for category in categories:\n",
    "                print(f\"======== {type_} - {category} ========\")\n",
    "                for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category, False)):\n",
    "                    if i > n:\n",
    "                        break\n",
    "                    print(batch[0][\"question\"], batch[0][\"answers\"])\n",
    "        gc.collect()\n",
    "        for type_ in types[1:]:\n",
    "            print(f\"======== {type_} - unfiltered ========\")\n",
    "            for i, batch in enumerate(dataset.yield_batch(batch_size, type_, \"web\", True)):\n",
    "                if i > n:\n",
    "                    break\n",
    "                print(batch[0][\"question\"], batch[0][\"answers\"])\n",
    "\n",
    "    # Test\n",
    "    logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "#     _test_race()\n",
    "#     _test_dream()\n",
    "#     _test_squad()\n",
    "#     _test_hotpotqa()\n",
    "#     _test_musique()\n",
    "    _test_triviaqa()\n",
    "    terminate_logger(logger)\n",
    "\n",
    "test_yield_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试model.generate_model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:54:10.485101Z",
     "start_time": "2024-10-08T12:54:08.592621Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:54:08,605 | base.py | INFO | Check data directory: D:\\resource\\data\\RACE\n",
      "2024-10-08 20:54:08,606 | base.py | INFO | √ ./train/high/\n",
      "2024-10-08 20:54:08,607 | base.py | INFO | √ ./train/middle/\n",
      "2024-10-08 20:54:08,607 | base.py | INFO | √ ./dev/high/\n",
      "2024-10-08 20:54:08,607 | base.py | INFO | √ ./dev/middle/\n",
      "2024-10-08 20:54:08,607 | base.py | INFO | √ ./test/high/\n",
      "2024-10-08 20:54:08,607 | base.py | INFO | √ ./test/middle/\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_test_race\n",
      "{'input_ids': tensor([[[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,    34,   203,   418,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,  3829,     5,  6464,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,  3829,     7,  8933,     5,   850,\n",
      "            227,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,    34,  1085,     7,   109,    53,\n",
      "           3482,     2]],\n",
      "\n",
      "        [[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    49,  1319,     9,  3482,    32,  1341,\n",
      "            430,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,  4157,   349,    97,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,   240,   282,    75,   907,   932,\n",
      "             13,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,   218,    75,    33,    86,    13,\n",
      "             24,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,    34,   203,   418,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,  3829,     5,  6464,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,  3829,     7,  8933,     5,   850,\n",
      "            227,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,   133,  1623,  3829,\n",
      "           3482,   142,  1437,  1437,    37,    34,  1085,     7,   109,    53,\n",
      "           3482,     2]],\n",
      "\n",
      "        [[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    49,  1319,     9,  3482,    32,  1341,\n",
      "            430,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,  4157,   349,    97,     4,  1437,\n",
      "            479,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,   240,   282,    75,   907,   932,\n",
      "             13,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2,  1213,   393,   213,\n",
      "           3482,   561,   142,  1437,    51,   218,    75,    33,    86,    13,\n",
      "             24,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,    16,   664,\n",
      "           1437,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,    16, 11640,\n",
      "             12,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,   747, 13585,\n",
      "             39,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,   630,    75,\n",
      "            101,     2]],\n",
      "\n",
      "        [[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,     5,  2792,    21,\n",
      "           1367,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,     5, 20976,  2294,\n",
      "            123,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,    37, 18774,   103,\n",
      "              9,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,    37,   851,    70,\n",
      "              5,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,    16,   664,\n",
      "           1437,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,    16, 11640,\n",
      "             12,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,   747, 13585,\n",
      "             39,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,    64,    75,\n",
      "            109,     5,  3482,   157,   142,  1437,  1437,    37,   630,    75,\n",
      "            101,     2]],\n",
      "\n",
      "        [[    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,     5,  2792,    21,\n",
      "           1367,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,     5, 20976,  2294,\n",
      "            123,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,    37, 18774,   103,\n",
      "              9,     2],\n",
      "         [    0,  2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,\n",
      "           6138,     7,   356,    23,   383,     2,     2, 35693,   399,    75,\n",
      "            907,    99,    39,   985,   770,   142,  1437,    37,   851,    70,\n",
      "              5,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2]],\n",
      "\n",
      "        [[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,     5,   750,     9,  6845,  4835,    11,  1444,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,   141,  6845,  1059,    10,  1406,  4076,    11,  1444,\n",
      "           1437,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,   141,     5, 24226,   300,     5, 10870,     9,  4835,\n",
      "           6845,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,  1005,     2,     2,   713,  9078,\n",
      "           4412, 14524,  1437,   141,  6845,    12,   958,    21,  2421,  1437,\n",
      "            479,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 32251,     9,     5,\n",
      "            511,    16,  1528,     9,     5,  7740,     9,  6845,    88,  1444,\n",
      "            116,     2]],\n",
      "\n",
      "        [[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,     5,   750,     9,  6845,  4835,    11,  1444,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,   141,  6845,  1059,    10,  1406,  4076,    11,  1444,\n",
      "           1437,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,   713,  9078,  4412,\n",
      "          14524,  1437,   141,     5, 24226,   300,     5, 10870,     9,  4835,\n",
      "           6845,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,  1005,     2,     2,   713,  9078,\n",
      "           4412, 14524,  1437,   141,  6845,    12,   958,    21,  2421,  1437,\n",
      "            479,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,  1005,     2,     2, 45866,  1059,\n",
      "             10,  1406,  4076,    11,  1444,  1437,    11, 46111,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11,   411, 33326,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11, 42081, 43169,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11,     5,   628, 42081, 43169,\n",
      "           3220,     2]],\n",
      "\n",
      "        [[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24, 29143,\n",
      "            101,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24, 29143,\n",
      "             55,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24,  1059,\n",
      "             10,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437, 38367,   263,\n",
      "          15206,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,  1005,     2,     2, 45866,  1059,\n",
      "             10,  1406,  4076,    11,  1444,  1437,    11, 46111,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11,   411, 33326,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11, 42081, 43169,  3220,  1437,\n",
      "            479,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2, 45866,  1059,    10,\n",
      "           1406,  4076,    11,  1444,  1437,    11,     5,   628, 42081, 43169,\n",
      "           3220,     2]],\n",
      "\n",
      "        [[    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24, 29143,\n",
      "            101,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24, 29143,\n",
      "             55,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437,    24,  1059,\n",
      "             10,     2],\n",
      "         [    0, 45866,  4835,    21,  1537,    11,   436,    13,   823,    65,\n",
      "           7673,   107,   137,  1268,    11,     2,     2,  4763,    11,  1005,\n",
      "            880,     7,  4076,  6845,    19,  5803,   142,  1437, 38367,   263,\n",
      "          15206,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2]],\n",
      "\n",
      "        [[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,   173,   203,  4851,  1437,\n",
      "            479,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,   216,   540,    59,    49,\n",
      "           2148,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437, 10628,    55,    86,    13,\n",
      "           1235,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,  1930,   540,    86,    19,\n",
      "             49,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2765, 16407,   514,\n",
      "             88,     5,  4946,     6,     5, 31887,   144,  1153,   770,     5,\n",
      "          20875,     2]],\n",
      "\n",
      "        [[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,   173,   203,  4851,  1437,\n",
      "            479,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,   216,   540,    59,    49,\n",
      "           2148,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437, 10628,    55,    86,    13,\n",
      "           1235,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,   170,  1532,    14,\n",
      "           1118,     7,  1791,     6, 15179,  1437,  1930,   540,    86,    19,\n",
      "             49,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "2024-10-08 20:54:09,082 | base.py | INFO | Check data directory: D:\\resource\\data\\dream\\data\n",
      "2024-10-08 20:54:09,083 | base.py | INFO | √ ./train.json\n",
      "2024-10-08 20:54:09,083 | base.py | INFO | √ ./dev.json\n",
      "2024-10-08 20:54:09,084 | base.py | INFO | √ ./test.json\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 42516,   111,   625, 36237,\n",
      "             12,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 42295,    12,  1246,   111,\n",
      "            625,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116,  3718,    12, 45260,   111,\n",
      "          46781,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 31613,   111, 45260,   111,\n",
      "            625,     2]],\n",
      "\n",
      "        [[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116,    20,  1808,     9,\n",
      "            301,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,  2655,     2,     2,  2264,    74,\n",
      "             28,     5,   275,  1270,    13,     5,  9078,   116, 11714,   358,\n",
      "           2289,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116,    20,  1808,     9,\n",
      "           4835,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116, 41183,   110,   113,\n",
      "          21033,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 42516,   111,   625, 36237,\n",
      "             12,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 42295,    12,  1246,   111,\n",
      "            625,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116,  3718,    12, 45260,   111,\n",
      "          46781,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    18,  1437,\n",
      "              5,  3184,     9,     5,  9078,   116, 31613,   111, 45260,   111,\n",
      "            625,     2]],\n",
      "\n",
      "        [[    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116,    20,  1808,     9,\n",
      "            301,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,  2655,     2,     2,  2264,    74,\n",
      "             28,     5,   275,  1270,    13,     5,  9078,   116, 11714,   358,\n",
      "           2289,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116,    20,  1808,     9,\n",
      "           4835,     2],\n",
      "         [    0, 11475,  2115,    10,    86,     6,    89,    21,    10, 20875,\n",
      "             54,   770,     7,  2364,    55,     2,     2,  2264,    74,    28,\n",
      "              5,   275,  1270,    13,     5,  9078,   116, 41183,   110,   113,\n",
      "          21033,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,   252,  6297,\n",
      "             31,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,    20,  5842,\n",
      "           4750,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,  5763,   747,\n",
      "            146,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,   252,    64,\n",
      "             75,     2]],\n",
      "\n",
      "        [[    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,  1701,     5, 20628,     9,   103,\n",
      "            390,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   213,    15, 14221, 16387,    71,\n",
      "            390,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   766, 16387,    71,   604,  1437,\n",
      "            479,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   356,    13,    10,    92,  5448,\n",
      "              7,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,   252,  6297,\n",
      "             31,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,    20,  5842,\n",
      "           4750,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,  5763,   747,\n",
      "            146,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2,  2264,  2594,     7,\n",
      "           1972,  1440, 25527,   309,     7,     5,  9078,   116,   252,    64,\n",
      "             75,     2]],\n",
      "\n",
      "        [[    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,  1701,     5, 20628,     9,   103,\n",
      "            390,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   213,    15, 14221, 16387,    71,\n",
      "            390,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   766, 16387,    71,   604,  1437,\n",
      "            479,     2],\n",
      "         [    0,  1779,  9911,     8,  3188,  6190,     5,  1880,  1726,    30,\n",
      "             10,  6874,  1437,  1440, 25527,     2,     2, 22649,  5086,   146,\n",
      "              5,  5842,  4750,  1437,  1437,   356,    13,    10,    92,  5448,\n",
      "              7,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "_test_dream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "2024-10-08 20:54:09,336 | base.py | INFO | Check data directory: D:\\resource\\data\\SQuAD\n",
      "2024-10-08 20:54:09,336 | base.py | INFO | √ ./squad1.1/train-v1.1.json\n",
      "2024-10-08 20:54:09,336 | base.py | INFO | √ ./squad1.1/dev-v1.1.json\n",
      "2024-10-08 20:54:09,336 | base.py | INFO | √ ./squad2.0/train-v2.0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[    0,   448,    35,    38,   524,  2811,  6614,   127,  7950,  1380,\n",
      "              4,    38,   524,    45,   442,     2,     2,  2264,   473,     5,\n",
      "            313,  3608,     5,   693,   109,   116, 15850,    69,  7950,  3254,\n",
      "              4,     2],\n",
      "         [    0,   448,    35,    38,   524,  2811,  6614,   127,  7950,  1380,\n",
      "              4,    38,   524,    45,   442,     2,     2,  2264,   473,     5,\n",
      "            313,  3608,     5,   693,   109,   116,  4624,    10,    55,  2679,\n",
      "           1380,     2],\n",
      "         [    0,   448,    35,    38,   524,  2811,  6614,   127,  7950,  1380,\n",
      "              4,    38,   524,    45,   442,     2,     2,  2264,   473,     5,\n",
      "            313,  3608,     5,   693,   109,   116,  5603,    69,  7950,  1380,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            313,   206,     9,     5,   693,    18,  6836,   116,    85,    18,\n",
      "            269,     2],\n",
      "         [    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            313,   206,     9,     5,   693,    18,  6836,   116,    85,    18,\n",
      "            182,     2],\n",
      "         [    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            313,   206,     9,     5,   693,    18,  6836,   116,    85,    18,\n",
      "            357,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,   448,    35,    38,   524,  2811,  6614,   127,  7950,  1380,\n",
      "              4,    38,   524,    45,   442,     2,     2,  2264,   473,     5,\n",
      "            313,  3608,     5,   693,   109,   116, 15850,    69,  7950,  3254,\n",
      "              4,     2],\n",
      "         [    0,   448,    35,    38,   524,  2811,  6614,   127,  7950,  1380,\n",
      "              4,    38,   524,    45,   442,     2,     2,  2264,   473,     5,\n",
      "            313,  3608,     5,   693,   109,   116,  4624,    10,    55,  2679,\n",
      "           1380,     2],\n",
      "         [    0,   448,    35,    38,   524,  2811,  6614,   127,  7950,  1380,\n",
      "              4,    38,   524,    45,   442,     2,     2,  2264,   473,     5,\n",
      "            313,  3608,     5,   693,   109,   116,  5603,    69,  7950,  1380,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            313,   206,     9,     5,   693,    18,  6836,   116,    85,    18,\n",
      "            269,     2],\n",
      "         [    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            313,   206,     9,     5,   693,    18,  6836,   116,    85,    18,\n",
      "            182,     2],\n",
      "         [    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            313,   206,     9,     5,   693,    18,  6836,   116,    85,    18,\n",
      "            357,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            693,  1394,     5,   313,     7,   109,   116, 40736,  6836,  2417,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            693,  1394,     5,   313,     7,   109,   116, 16827,    39,  1141,\n",
      "            220,     2],\n",
      "         [    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            693,  1394,     5,   313,     7,   109,   116,  6319,   103, 14532,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   448,    35,  6893,    23,     5,  1816,    15,     5,  4806,\n",
      "            328, 50118,   597,    35,  5534,     6,  4420,    79,    18,   269,\n",
      "             10,     2,     2, 13841,    32,     5,    80,  5151,   116,   497,\n",
      "            184,     2],\n",
      "         [    0,   448,    35,  6893,    23,     5,  1816,    15,     5,  4806,\n",
      "            328, 50118,   597,    35,  5534,     6,  4420,    79,    18,   269,\n",
      "              2,     2, 13841,    32,     5,    80,  5151,   116,    96,    49,\n",
      "           8171,     2],\n",
      "         [    0,   448,    35,  6893,    23,     5,  1816,    15,     5,  4806,\n",
      "            328, 50118,   597,    35,  5534,     6,  4420,    79,    18,   269,\n",
      "              2,     2, 13841,    32,     5,    80,  5151,   116,   374,     5,\n",
      "           2014,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            693,  1394,     5,   313,     7,   109,   116, 40736,  6836,  2417,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            693,  1394,     5,   313,     7,   109,   116, 16827,    39,  1141,\n",
      "            220,     2],\n",
      "         [    0,   771,    35,  2647,     6,    38,   437,  6023,   127,  6836,\n",
      "            965,    75,     7,   110,  5840,     2,     2,  2264,   473,     5,\n",
      "            693,  1394,     5,   313,     7,   109,   116,  6319,   103, 14532,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   448,    35,  6893,    23,     5,  1816,    15,     5,  4806,\n",
      "            328, 50118,   597,    35,  5534,     6,  4420,    79,    18,   269,\n",
      "             10,     2,     2, 13841,    32,     5,    80,  5151,   116,   497,\n",
      "            184,     2],\n",
      "         [    0,   448,    35,  6893,    23,     5,  1816,    15,     5,  4806,\n",
      "            328, 50118,   597,    35,  5534,     6,  4420,    79,    18,   269,\n",
      "              2,     2, 13841,    32,     5,    80,  5151,   116,    96,    49,\n",
      "           8171,     2],\n",
      "         [    0,   448,    35,  6893,    23,     5,  1816,    15,     5,  4806,\n",
      "            328, 50118,   597,    35,  5534,     6,  4420,    79,    18,   269,\n",
      "              2,     2, 13841,    32,     5,    80,  5151,   116,   374,     5,\n",
      "           2014,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0,   448,    35,  2615,    47, 20453,   162,   150,    38,   524,\n",
      "           6970,     4, 50118,   771,    35,     2,     2,  2264,   473,     5,\n",
      "            313,   236,     5,   693,     7,   109,   116,   598,   310,     5,\n",
      "          13305,     2],\n",
      "         [    0,   448,    35,  2615,    47, 20453,   162,   150,    38,   524,\n",
      "           6970,     4, 50118,   771,    35,     2,     2,  2264,   473,     5,\n",
      "            313,   236,     5,   693,     7,   109,   116,   598,   492,    10,\n",
      "            819,     2],\n",
      "         [    0,   448,    35,  2615,    47, 20453,   162,   150,    38,   524,\n",
      "           6970,     4, 50118,   771,    35,     2,     2,  2264,   473,     5,\n",
      "            313,   236,     5,   693,     7,   109,   116,   598,  7884,    10,\n",
      "           2214,     2]],\n",
      "\n",
      "        [[    0,   771,    35,    38,    64,    75,  1955,    66,    99,    18,\n",
      "           1593,    19,   127,  1183,     4,     2,     2,  2264,   473,     5,\n",
      "            313,  1266,   116,    85,    40,   185,    59,    65,   353,     7,\n",
      "           5989,     2],\n",
      "         [    0,   771,    35,    38,    64,    75,  1955,    66,    99,    18,\n",
      "           1593,    19,   127,  1183,     4,     2,     2,  2264,   473,     5,\n",
      "            313,  1266,   116,    20,  1183,    16,   117,  1181,   966, 26643,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,    38,    64,    75,  1955,    66,    99,    18,\n",
      "           1593,    19,   127,  1183,     4,     2,     2,  2264,   473,     5,\n",
      "            313,  1266,   116,    85,    16,    10,   205,  1114,     7,   489,\n",
      "              5,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,   448,    35,  2615,    47, 20453,   162,   150,    38,   524,\n",
      "           6970,     4, 50118,   771,    35,     2,     2,  2264,   473,     5,\n",
      "            313,   236,     5,   693,     7,   109,   116,   598,   310,     5,\n",
      "          13305,     2],\n",
      "         [    0,   448,    35,  2615,    47, 20453,   162,   150,    38,   524,\n",
      "           6970,     4, 50118,   771,    35,     2,     2,  2264,   473,     5,\n",
      "            313,   236,     5,   693,     7,   109,   116,   598,   492,    10,\n",
      "            819,     2],\n",
      "         [    0,   448,    35,  2615,    47, 20453,   162,   150,    38,   524,\n",
      "           6970,     4, 50118,   771,    35,     2,     2,  2264,   473,     5,\n",
      "            313,   236,     5,   693,     7,   109,   116,   598,  7884,    10,\n",
      "           2214,     2]],\n",
      "\n",
      "        [[    0,   771,    35,    38,    64,    75,  1955,    66,    99,    18,\n",
      "           1593,    19,   127,  1183,     4,     2,     2,  2264,   473,     5,\n",
      "            313,  1266,   116,    85,    40,   185,    59,    65,   353,     7,\n",
      "           5989,     2],\n",
      "         [    0,   771,    35,    38,    64,    75,  1955,    66,    99,    18,\n",
      "           1593,    19,   127,  1183,     4,     2,     2,  2264,   473,     5,\n",
      "            313,  1266,   116,    20,  1183,    16,   117,  1181,   966, 26643,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,    38,    64,    75,  1955,    66,    99,    18,\n",
      "           1593,    19,   127,  1183,     4,     2,     2,  2264,   473,     5,\n",
      "            313,  1266,   116,    85,    16,    10,   205,  1114,     7,   489,\n",
      "              5,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,   244,    47,   116, 50118,     2,\n",
      "              2, 13841,   473,     5,   693,   173,   116,   497,    10,  2737,\n",
      "              4,     2],\n",
      "         [    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,   244,    47,   116,     2,     2,\n",
      "          13841,   473,     5,   693,   173,   116,   497,    10,  1012,  1992,\n",
      "              4,     2],\n",
      "         [    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,   244,    47,   116,     2,     2,\n",
      "          13841,   473,     5,   693,   173,   116,   497,    10,  2924,   558,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,     2,     2,  7608,    16,     5,\n",
      "            313,  9889,    13,    42,   737,   116,    91,   782,    10,   157,\n",
      "             12,     2],\n",
      "         [    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,     2,     2,  7608,    16,     5,\n",
      "            313,  9889,    13,    42,   737,   116,    91,    34,   682,   685,\n",
      "            277,     2],\n",
      "         [    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,     2,     2,  7608,    16,     5,\n",
      "            313,  9889,    13,    42,   737,   116,    91,  1072,   103,   447,\n",
      "            676,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,   244,    47,   116, 50118,     2,\n",
      "              2, 13841,   473,     5,   693,   173,   116,   497,    10,  2737,\n",
      "              4,     2],\n",
      "         [    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,   244,    47,   116,     2,     2,\n",
      "          13841,   473,     5,   693,   173,   116,   497,    10,  1012,  1992,\n",
      "              4,     2],\n",
      "         [    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,   244,    47,   116,     2,     2,\n",
      "          13841,   473,     5,   693,   173,   116,   497,    10,  2924,   558,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,     2,     2,  7608,    16,     5,\n",
      "            313,  9889,    13,    42,   737,   116,    91,   782,    10,   157,\n",
      "             12,     2],\n",
      "         [    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,     2,     2,  7608,    16,     5,\n",
      "            313,  9889,    13,    42,   737,   116,    91,    34,   682,   685,\n",
      "            277,     2],\n",
      "         [    0,   771,    35, 20920,     6,    42,    16,   255,  3573, 10276,\n",
      "          11863,     4,  1336,    64,    38,     2,     2,  7608,    16,     5,\n",
      "            313,  9889,    13,    42,   737,   116,    91,  1072,   103,   447,\n",
      "            676,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0,   448,    35,    38,   206,    24,    18,   164,     7,  1895,\n",
      "              4, 50118,   771,    35,    38,  4443,    98,     4,    20,     2,\n",
      "              2,  2264,    16,     5,  1650,   101,   116,    85,    18, 31832,\n",
      "              4,     2],\n",
      "         [    0,   448,    35,    38,   206,    24,    18,   164,     7,  1895,\n",
      "              4, 50118,   771,    35,    38,  4443,    98,     4,    20,     2,\n",
      "              2,  2264,    16,     5,  1650,   101,   116,    85,    18,  2779,\n",
      "              4,     2],\n",
      "         [    0,   448,    35,    38,   206,    24,    18,   164,     7,  1895,\n",
      "              4, 50118,   771,    35,    38,  4443,    98,     4,    20,     2,\n",
      "              2,  2264,    16,     5,  1650,   101,   116,    85,    18,  5419,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   771,    35,  7204,  8429,     4,  2615,    38,   244,    47,\n",
      "            116, 50118,   448,    35,  8976,     6, 20280,     6,    42,     2,\n",
      "              2, 13841,    32,     5,    80,  6864,   116,    96,    10,  2391,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,  7204,  8429,     4,  2615,    38,   244,    47,\n",
      "            116, 50118,   448,    35,  8976,     6, 20280,     6,    42,     2,\n",
      "              2, 13841,    32,     5,    80,  6864,   116,    96,    10,  2303,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,  7204,  8429,     4,  2615,    38,   244,    47,\n",
      "            116, 50118,   448,    35,  8976,     6, 20280,     6,    42,     2,\n",
      "              2, 13841,    32,     5,    80,  6864,   116,    96,     5,  2014,\n",
      "              4,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,   448,    35,    38,   206,    24,    18,   164,     7,  1895,\n",
      "              4, 50118,   771,    35,    38,  4443,    98,     4,    20,     2,\n",
      "              2,  2264,    16,     5,  1650,   101,   116,    85,    18, 31832,\n",
      "              4,     2],\n",
      "         [    0,   448,    35,    38,   206,    24,    18,   164,     7,  1895,\n",
      "              4, 50118,   771,    35,    38,  4443,    98,     4,    20,     2,\n",
      "              2,  2264,    16,     5,  1650,   101,   116,    85,    18,  2779,\n",
      "              4,     2],\n",
      "         [    0,   448,    35,    38,   206,    24,    18,   164,     7,  1895,\n",
      "              4, 50118,   771,    35,    38,  4443,    98,     4,    20,     2,\n",
      "              2,  2264,    16,     5,  1650,   101,   116,    85,    18,  5419,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   771,    35,  7204,  8429,     4,  2615,    38,   244,    47,\n",
      "            116, 50118,   448,    35,  8976,     6, 20280,     6,    42,     2,\n",
      "              2, 13841,    32,     5,    80,  6864,   116,    96,    10,  2391,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,  7204,  8429,     4,  2615,    38,   244,    47,\n",
      "            116, 50118,   448,    35,  8976,     6, 20280,     6,    42,     2,\n",
      "              2, 13841,    32,     5,    80,  6864,   116,    96,    10,  2303,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,  7204,  8429,     4,  2615,    38,   244,    47,\n",
      "            116, 50118,   448,    35,  8976,     6, 20280,     6,    42,     2,\n",
      "              2, 13841,    32,     5,    80,  6864,   116,    96,     5,  2014,\n",
      "              4,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0,   448,    35,   520,   222,    47,    78,   465,     5,  1883,\n",
      "           3187,     8,   383,  1716,   116, 50118,   771,    35,   572,     2,\n",
      "              2,  2264,    32,    51,  1686,    59,   116,    83,  1703,  3213,\n",
      "              4,     2],\n",
      "         [    0,   448,    35,   520,   222,    47,    78,   465,     5,  1883,\n",
      "           3187,     8,   383,  1716,   116, 50118,   771,    35,   572,    38,\n",
      "              2,     2,  2264,    32,    51,  1686,    59,   116,    83,   668,\n",
      "              4,     2],\n",
      "         [    0,   448,    35,   520,   222,    47,    78,   465,     5,  1883,\n",
      "           3187,     8,   383,  1716,   116, 50118,   771,    35,   572,    38,\n",
      "              2,     2,  2264,    32,    51,  1686,    59,   116,    83,  1846,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   597,    35,    20, 17299,    40,   386,    23,   130,    42,\n",
      "           1390,     6,    16,    14,   235,     2,     2,  2264,   109,    47,\n",
      "            216,    59,     5, 17299,   116,    85,    40,   386,    23,   130,\n",
      "             42,     2],\n",
      "         [    0,   597,    35,    20, 17299,    40,   386,    23,   130,    42,\n",
      "           1390,     6,    16,    14,   235,     2,     2,  2264,   109,    47,\n",
      "            216,    59,     5, 17299,   116,    85,    40,   386,    23,   130,\n",
      "           3859,     2],\n",
      "         [    0,   597,    35,    20, 17299,    40,   386,    23,   130,    42,\n",
      "           1390,     6,    16,    14,   235,     2,     2,  2264,   109,    47,\n",
      "            216,    59,     5, 17299,   116,    85,    40,   386,    23,   799,\n",
      "           3859,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,   448,    35,   520,   222,    47,    78,   465,     5,  1883,\n",
      "           3187,     8,   383,  1716,   116, 50118,   771,    35,   572,     2,\n",
      "              2,  2264,    32,    51,  1686,    59,   116,    83,  1703,  3213,\n",
      "              4,     2],\n",
      "         [    0,   448,    35,   520,   222,    47,    78,   465,     5,  1883,\n",
      "           3187,     8,   383,  1716,   116, 50118,   771,    35,   572,    38,\n",
      "              2,     2,  2264,    32,    51,  1686,    59,   116,    83,   668,\n",
      "              4,     2],\n",
      "         [    0,   448,    35,   520,   222,    47,    78,   465,     5,  1883,\n",
      "           3187,     8,   383,  1716,   116, 50118,   771,    35,   572,    38,\n",
      "              2,     2,  2264,    32,    51,  1686,    59,   116,    83,  1846,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   597,    35,    20, 17299,    40,   386,    23,   130,    42,\n",
      "           1390,     6,    16,    14,   235,     2,     2,  2264,   109,    47,\n",
      "            216,    59,     5, 17299,   116,    85,    40,   386,    23,   130,\n",
      "             42,     2],\n",
      "         [    0,   597,    35,    20, 17299,    40,   386,    23,   130,    42,\n",
      "           1390,     6,    16,    14,   235,     2,     2,  2264,   109,    47,\n",
      "            216,    59,     5, 17299,   116,    85,    40,   386,    23,   130,\n",
      "           3859,     2],\n",
      "         [    0,   597,    35,    20, 17299,    40,   386,    23,   130,    42,\n",
      "           1390,     6,    16,    14,   235,     2,     2,  2264,   109,    47,\n",
      "            216,    59,     5, 17299,   116,    85,    40,   386,    23,   799,\n",
      "           3859,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "{'input_ids': tensor([[[    0,   771,    35,    38,  2813,    38,  1467,     5,   498,     9,\n",
      "              5,  7717,     7,   928,     4,   125,     2,     2,  2264,    16,\n",
      "              5,   313,   164,     7,   109,   116,  2381,    15,     5,  3742,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,    38,  2813,    38,  1467,     5,   498,     9,\n",
      "              5,  7717,     7,   928,     4,   125,     2,     2,  2264,    16,\n",
      "              5,   313,   164,     7,   109,   116,  5293,    10,  1028,   486,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,    38,  2813,    38,  1467,     5,   498,     9,\n",
      "              5,  7717,     7,   928,     4,   125,     2,     2,  2264,    16,\n",
      "              5,   313,   164,     7,   109,   116,  4624,    10,  2341,  1805,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   448,    35, 11258,    47,  1004,   160,     5,  8054,  6700,\n",
      "            116, 50118,   771,    35, 12191,     6,    53,    47,    26,     2,\n",
      "              2, 17485,     5,   693,  1004,   160,     5,  6700,   116, 20240,\n",
      "              4,     2],\n",
      "         [    0,   448,    35, 11258,    47,  1004,   160,     5,  8054,  6700,\n",
      "            116, 50118,   771,    35, 12191,     6,    53,    47,    26,     2,\n",
      "              2, 17485,     5,   693,  1004,   160,     5,  6700,   116,  5359,\n",
      "              4,     2],\n",
      "         [    0,   448,    35, 11258,    47,  1004,   160,     5,  8054,  6700,\n",
      "            116, 50118,   771,    35, 12191,     6,    53,    47,    26,     2,\n",
      "              2, 17485,     5,   693,  1004,   160,     5,  6700,   116,   440,\n",
      "              4,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[[    0,   771,    35,    38,  2813,    38,  1467,     5,   498,     9,\n",
      "              5,  7717,     7,   928,     4,   125,     2,     2,  2264,    16,\n",
      "              5,   313,   164,     7,   109,   116,  2381,    15,     5,  3742,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,    38,  2813,    38,  1467,     5,   498,     9,\n",
      "              5,  7717,     7,   928,     4,   125,     2,     2,  2264,    16,\n",
      "              5,   313,   164,     7,   109,   116,  5293,    10,  1028,   486,\n",
      "              4,     2],\n",
      "         [    0,   771,    35,    38,  2813,    38,  1467,     5,   498,     9,\n",
      "              5,  7717,     7,   928,     4,   125,     2,     2,  2264,    16,\n",
      "              5,   313,   164,     7,   109,   116,  4624,    10,  2341,  1805,\n",
      "              4,     2]],\n",
      "\n",
      "        [[    0,   448,    35, 11258,    47,  1004,   160,     5,  8054,  6700,\n",
      "            116, 50118,   771,    35, 12191,     6,    53,    47,    26,     2,\n",
      "              2, 17485,     5,   693,  1004,   160,     5,  6700,   116, 20240,\n",
      "              4,     2],\n",
      "         [    0,   448,    35, 11258,    47,  1004,   160,     5,  8054,  6700,\n",
      "            116, 50118,   771,    35, 12191,     6,    53,    47,    26,     2,\n",
      "              2, 17485,     5,   693,  1004,   160,     5,  6700,   116,  5359,\n",
      "              4,     2],\n",
      "         [    0,   448,    35, 11258,    47,  1004,   160,     5,  8054,  6700,\n",
      "            116, 50118,   771,    35, 12191,     6,    53,    47,    26,     2,\n",
      "              2, 17485,     5,   693,  1004,   160,     5,  6700,   116,   440,\n",
      "              4,     2]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}\n",
      "################################\n",
      "_test_squad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:54:09,549 | base.py | INFO | Check data directory: D:\\resource\\data\\HotpotQA\n",
      "2024-10-08 20:54:09,549 | base.py | INFO | √ ./hotpot_dev_distractor_v1.json\n",
      "2024-10-08 20:54:09,549 | base.py | INFO | √ ./hotpot_dev_fullwiki_v1.json\n",
      "2024-10-08 20:54:09,549 | base.py | INFO | √ ./hotpot_test_fullwiki_v1.json\n",
      "2024-10-08 20:54:09,555 | base.py | INFO | √ ./hotpot_train_v1.1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0, 32251,  1485,   165,  4625,     5,  9601,    23,  1582,  2616,\n",
      "           654,   116,     2,     2, 16713,  1215,   387, 20734,  1215,  1096,\n",
      "         50118, 16713,  2616,   654,    21,    41,   470,  1037,   177,     7,\n",
      "          3094,     2],\n",
      "        [    0, 32251,  1485,   165,  4625,     5, 11119,    23,  1582,  2616,\n",
      "           654,   116,     2,     2, 16713,  1215,   387, 20734,  1215,  1096,\n",
      "         50118, 16713,  2616,   654,    21,    41,   470,  1037,   177,     7,\n",
      "          3094,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[    0, 32251,  1485,   165,  4625,     5,  9601,    23,  1582,  2616,\n",
      "           654,   116,     2,     2, 16713,  1215,   387, 20734,  1215,  1096,\n",
      "         50118, 16713,  2616,   654,    21,    41,   470,  1037,   177,     7,\n",
      "          3094,     2],\n",
      "        [    0, 32251,  1485,   165,  4625,     5, 11119,    23,  1582,  2616,\n",
      "           654,   116,     2,     2, 16713,  1215,   387, 20734,  1215,  1096,\n",
      "         50118, 16713,  2616,   654,    21,    41,   470,  1037,   177,     7,\n",
      "          3094,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "################################\n",
      "{'input_ids': tensor([[    0, 13841,   222,  1582,  2616,   654,   185,   317,   116,     2,\n",
      "             2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,\n",
      "           654,    21,    41,   470,  1037,   177,     7,  3094,     5,  2234,\n",
      "             9,     2],\n",
      "        [    0, 32251,  1485,   165,   351,  1582,  2616,   654,   116,     2,\n",
      "             2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,\n",
      "           654,    21,    41,   470,  1037,   177,     7,  3094,     5,  2234,\n",
      "             9,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[    0, 13841,   222,  1582,  2616,   654,   185,   317,   116,     2,\n",
      "             2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,\n",
      "           654,    21,    41,   470,  1037,   177,     7,  3094,     5,  2234,\n",
      "             9,     2],\n",
      "        [    0, 32251,  1485,   165,   351,  1582,  2616,   654,   116,     2,\n",
      "             2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,\n",
      "           654,    21,    41,   470,  1037,   177,     7,  3094,     5,  2234,\n",
      "             9,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "################################\n",
      "{'input_ids': tensor([[    0,  2264,  3195,    21,   341,     7, 20251,     5,   654,   212,\n",
      "          4038,     9,     5,  1582,  2616,     2,     2, 16713,  1215,   387,\n",
      "         20734,  1215,  1096, 50118, 16713,  2616,   654,    21,    41,   470,\n",
      "          1037,     2],\n",
      "        [    0,  2264,    21,     5,  4782,     9,  1582,  2616,   654,   116,\n",
      "             2,     2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,\n",
      "          2616,   654,    21,    41,   470,  1037,   177,     7,  3094,     5,\n",
      "          2234,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[    0,  2264,  3195,    21,   341,     7, 20251,     5,   654,   212,\n",
      "          4038,     9,     5,  1582,  2616,     2,     2, 16713,  1215,   387,\n",
      "         20734,  1215,  1096, 50118, 16713,  2616,   654,    21,    41,   470,\n",
      "          1037,     2],\n",
      "        [    0,  2264,    21,     5,  4782,     9,  1582,  2616,   654,   116,\n",
      "             2,     2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,\n",
      "          2616,   654,    21,    41,   470,  1037,   177,     7,  3094,     5,\n",
      "          2234,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "################################\n",
      "{'input_ids': tensor([[    0,  2264,   183,    21,     5,   177,   702,    15,   116,     2,\n",
      "             2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,\n",
      "           654,    21,    41,   470,  1037,   177,     7,  3094,     5,  2234,\n",
      "             9,     2],\n",
      "        [    0,  2264,    16,     5,  9601,   765,    13,   116,     2,     2,\n",
      "         16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,   654,\n",
      "            21,    41,   470,  1037,   177,     7,  3094,     5,  2234,     9,\n",
      "             5,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[    0,  2264,   183,    21,     5,   177,   702,    15,   116,     2,\n",
      "             2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,\n",
      "           654,    21,    41,   470,  1037,   177,     7,  3094,     5,  2234,\n",
      "             9,     2],\n",
      "        [    0,  2264,    16,     5,  9601,   765,    13,   116,     2,     2,\n",
      "         16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,   654,\n",
      "            21,    41,   470,  1037,   177,     7,  3094,     5,  2234,     9,\n",
      "             5,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "################################\n",
      "{'input_ids': tensor([[    0,  2264,    21,     5,  4782,     9,  1582,  2616,   654,   116,\n",
      "             2,     2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,\n",
      "          2616,   654,    21,    41,   470,  1037,   177,     7,  3094,     5,\n",
      "          2234,     2],\n",
      "        [    0,  2264,   473,  9601,  1413,    13,   116,     2,     2, 16713,\n",
      "          1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,   654,    21,\n",
      "            41,   470,  1037,   177,     7,  3094,     5,  2234,     9,     5,\n",
      "           496,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[    0,  2264,    21,     5,  4782,     9,  1582,  2616,   654,   116,\n",
      "             2,     2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,\n",
      "          2616,   654,    21,    41,   470,  1037,   177,     7,  3094,     5,\n",
      "          2234,     2],\n",
      "        [    0,  2264,   473,  9601,  1413,    13,   116,     2,     2, 16713,\n",
      "          1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,   654,    21,\n",
      "            41,   470,  1037,   177,     7,  3094,     5,  2234,     9,     5,\n",
      "           496,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "################################\n",
      "{'input_ids': tensor([[    0,  2264,   183,    21,     5,  1582,  2616,   702,    15,   116,\n",
      "             2,     2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,\n",
      "          2616,   654,    21,    41,   470,  1037,   177,     7,  3094,     5,\n",
      "          2234,     2],\n",
      "        [    0, 12375,   351,  1582,  2616,   654,   116,     2,     2, 16713,\n",
      "          1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,   654,    21,\n",
      "            41,   470,  1037,   177,     7,  3094,     5,  2234,     9,     5,\n",
      "           496,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[    0,  2264,   183,    21,     5,  1582,  2616,   702,    15,   116,\n",
      "             2,     2, 16713,  1215,   387, 20734,  1215,  1096, 50118, 16713,\n",
      "          2616,   654,    21,    41,   470,  1037,   177,     7,  3094,     5,\n",
      "          2234,     2],\n",
      "        [    0, 12375,   351,  1582,  2616,   654,   116,     2,     2, 16713,\n",
      "          1215,   387, 20734,  1215,  1096, 50118, 16713,  2616,   654,    21,\n",
      "            41,   470,  1037,   177,     7,  3094,     5,  2234,     9,     5,\n",
      "           496,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "################################\n",
      "{'input_ids': tensor([[    0,  2264,  5584,   222,  1582,  2616,   654,   185,   317,    11,\n",
      "           116,     2,     2, 16713,  1215,   387, 20734,  1215,  1096, 50118,\n",
      "         16713,  2616,   654,    21,    41,   470,  1037,   177,     7,  3094,\n",
      "             5,     2],\n",
      "        [    0,  2264,   343,   222,  1582,  2616,   654,   185,   317,    11,\n",
      "           116,     2,     2, 16713,  1215,   387, 20734,  1215,  1096, 50118,\n",
      "         16713,  2616,   654,    21,    41,   470,  1037,   177,     7,  3094,\n",
      "             5,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[    0,  2264,  5584,   222,  1582,  2616,   654,   185,   317,    11,\n",
      "           116,     2,     2, 16713,  1215,   387, 20734,  1215,  1096, 50118,\n",
      "         16713,  2616,   654,    21,    41,   470,  1037,   177,     7,  3094,\n",
      "             5,     2],\n",
      "        [    0,  2264,   343,   222,  1582,  2616,   654,   185,   317,    11,\n",
      "           116,     2,     2, 16713,  1215,   387, 20734,  1215,  1096, 50118,\n",
      "         16713,  2616,   654,    21,    41,   470,  1037,   177,     7,  3094,\n",
      "             5,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "################################\n",
      "_test_hotpotqa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[64790, 64792,   809,  ...,   267,  3764, 30953],\n",
      "        [64790, 64792,   809,  ...,    13,  1036,  1147]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'position_ids': tensor([[  0,   1,   2,  ..., 509, 510, 511],\n",
      "        [  0,   1,   2,  ..., 509, 510, 511]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939],\n",
      "        [64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'position_ids': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]])}\n",
      "################################\n",
      "{'input_ids': tensor([[64790, 64792,   809,  ...,  1669,   290,   709],\n",
      "        [64790, 64792,   809,  ..., 30945,   428, 30910]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'position_ids': tensor([[  0,   1,   2,  ..., 509, 510, 511],\n",
      "        [  0,   1,   2,  ..., 509, 510, 511]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939],\n",
      "        [64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'position_ids': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]])}\n",
      "################################\n",
      "{'input_ids': tensor([[64790, 64792,   809,  ...,   910, 11028,  2575],\n",
      "        [64790, 64792,   809,  ...,   314, 30967, 30937]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'position_ids': tensor([[  0,   1,   2,  ..., 509, 510, 511],\n",
      "        [  0,   1,   2,  ..., 509, 510, 511]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939],\n",
      "        [64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'position_ids': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]])}\n",
      "################################\n",
      "{'input_ids': tensor([[64790, 64792,   809,  ...,   323,   284,  1603],\n",
      "        [64790, 64792,   809,  ...,  9781,   649,    13]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'position_ids': tensor([[  0,   1,   2,  ..., 509, 510, 511],\n",
      "        [  0,   1,   2,  ..., 509, 510, 511]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939],\n",
      "        [64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'position_ids': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]])}\n",
      "################################\n",
      "{'input_ids': tensor([[64790, 64792,   809,  ..., 30943, 30940, 30939],\n",
      "        [64790, 64792,   809,  ...,    13,   353,  2310]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'position_ids': tensor([[  0,   1,   2,  ..., 509, 510, 511],\n",
      "        [  0,   1,   2,  ..., 509, 510, 511]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939],\n",
      "        [64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'position_ids': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]])}\n",
      "################################\n",
      "{'input_ids': tensor([[64790, 64792,   809,  ..., 30932, 11057,   293],\n",
      "        [64790, 64792,   809,  ..., 30913,   293,   319]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'position_ids': tensor([[  0,   1,   2,  ..., 509, 510, 511],\n",
      "        [  0,   1,   2,  ..., 509, 510, 511]])}\n",
      "--------------------------------\n",
      "{'input_ids': tensor([[64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939],\n",
      "        [64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'position_ids': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]])}\n",
      "################################\n",
      "{'input_ids': tensor([[64790, 64792,   809,  ..., 30932,   473,   394],\n",
      "        [64790, 64792,   809,  ...,   267,   550,  1109]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'position_ids': tensor([[  0,   1,   2,  ..., 509, 510, 511],\n",
      "        [  0,   1,   2,  ..., 509, 510, 511]])}\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939],\n",
      "        [64790, 64792,   809,   383,   260,  7486, 30932,   344,   720,   289,\n",
      "           950,   267,  1845,  4177,  7724,   293,  7511,   267,  3238,   289,\n",
      "           267,  2021,  3040, 30930,    13,   986,  8192, 30954,    13, 11355,\n",
      "         30910, 30939]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'position_ids': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]])}\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "def test_generate_model_inputs():\n",
    "\n",
    "    def _test_race():\n",
    "        print(_test_race.__name__)\n",
    "        data_dir = DATA_SUMMARY[RaceDataset.dataset_name][\"path\"]\n",
    "        model_path = MODEL_SUMMARY[RobertaLargeFinetunedRace.model_name][\"path\"]\n",
    "        # model_path = MODEL_SUMMARY[LongformerLarge4096AnsweringRace.model_name][\"path\"]\n",
    "        dataset = RaceDataset(data_dir)\n",
    "        model = RobertaLargeFinetunedRace(model_path, device=\"cpu\")\n",
    "        # model = LongformerLarge4096AnsweringRace(model_path, device=\"cpu\")\n",
    "\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"], difficulties=[\"high\"])):\n",
    "            model_inputs = RaceDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    def _test_dream():\n",
    "        print(_test_dream.__name__)\n",
    "        data_dir = DATA_SUMMARY[DreamDataset.dataset_name][\"path\"] \n",
    "        model_path = MODEL_SUMMARY[RobertaLargeFinetunedRace.model_name][\"path\"]\n",
    "        dataset = DreamDataset(data_dir)\n",
    "        model = RobertaLargeFinetunedRace(model_path, device=\"cpu\")\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"])):\n",
    "            model_inputs = DreamDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    def _test_squad():\n",
    "        print(_test_squad.__name__)\n",
    "        data_dir = DATA_SUMMARY[SquadDataset.dataset_name][\"path\"]\n",
    "        model_path = MODEL_SUMMARY[RobertaBaseSquad2.model_name][\"path\"]\n",
    "        dataset = SquadDataset(data_dir)\n",
    "        model = RobertaBaseSquad2(model_path, device=\"cpu\")\n",
    "\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, type_=\"dev\", version=\"1.1\")):\n",
    "            model_inputs = SquadDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    def _test_hotpotqa():\n",
    "        print(_test_hotpotqa.__name__)\n",
    "        data_dir = DATA_SUMMARY[HotpotqaDataset.dataset_name][\"path\"]\n",
    "        model_path = MODEL_SUMMARY[Chatglm26bInt4.model_name][\"path\"]\n",
    "        dataset = HotpotqaDataset(data_dir)\n",
    "        model = Chatglm6bInt4(model_path, device=\"cuda\")\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, filename=\"dev_distractor_v1.json\")):\n",
    "            model_inputs = HotpotqaDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=512)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\t\t\n",
    "\n",
    "    logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "    _test_race()\n",
    "    _test_dream()\n",
    "    _test_squad()\n",
    "    _test_hotpotqa()\n",
    "    terminate_logger(logger)\n",
    "\n",
    "test_generate_model_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试pipeline.easy_inference_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference_pipeline():\n",
    "\n",
    "    def _test_race():\n",
    "        race_pipeline = RacePipeline()\n",
    "        pipeline = race_pipeline.easy_inference_pipeline(\n",
    "            dataset_class_name = \"RaceDataset\",\n",
    "            model_class_name = \"RobertaLargeFinetunedRace\",\n",
    "            batch_size = 2,\n",
    "            dataset_kwargs = {\"types\": [\"train\"], \"difficulties\": [\"high\", \"middle\"]},\n",
    "            model_kwargs = {\"max_length\": 512},\n",
    "        )\n",
    "\n",
    "    def _test_squad():\n",
    "        squad_pipeline = SquadPipeline()\n",
    "        pipeline = squad_pipeline.easy_inference_pipeline(\n",
    "            dataset_class_name = \"SquadDataset\",\n",
    "            model_class_name = \"RobertaBaseSquad2\",\n",
    "            batch_size = 2,\n",
    "            dataset_kwargs = {\"type_\": \"train\", \"version\": \"2.0\"},\n",
    "            model_kwargs = {\"max_length\": 512},\n",
    "        )\n",
    "\n",
    "    # logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "    _test_race()\n",
    "    # _test_squad()\n",
    "    # terminate_logger(logger)\n",
    "    \n",
    "    \n",
    "test_inference_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-adapters-jupyter",
   "language": "python",
   "name": "py39-adapters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
