{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#测试dataset.yield_batch\" data-toc-modified-id=\"测试dataset.yield_batch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>测试dataset.yield_batch</a></span></li><li><span><a href=\"#测试model.generate_model_inputs\" data-toc-modified-id=\"测试model.generate_model_inputs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>测试model.generate_model_inputs</a></span></li><li><span><a href=\"#测试pipeline.easy_inference_pipeline\" data-toc-modified-id=\"测试pipeline.easy_inference_pipeline-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>测试pipeline.easy_inference_pipeline</a></span></li><li><span><a href=\"#测试modules\" data-toc-modified-id=\"测试modules-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>测试modules</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T03:16:58.825465Z",
     "start_time": "2024-10-17T03:16:53.601049Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py39-adapters\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "E:\\Anaconda3\\envs\\py39-adapters\\lib\\site-packages\\transformers\\utils\\hub.py:127: FutureWarning: Using `PYTORCH_PRETRAINED_BERT_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: D:\\code\\python\\project\\caoyang\\project_019_llm_reasoning\\easyqa\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 切换工作目录\n",
    "if not \"CHDIR_FLAG\" in dir():\n",
    "    os.chdir(\"../\")\n",
    "    CHDIR_FLAG = True\n",
    "else:\n",
    "    assert CHDIR_FLAG is True, CHDIR_FLAG\n",
    "\n",
    "# 导入必要的包\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from configs import ModuleConfig\n",
    "from settings import DATA_DIR, LOG_DIR, MODEL_ROOT, DATA_SUMMARY, MODEL_SUMMARY\n",
    "\n",
    "from src.datasets import RaceDataset, DreamDataset, SquadDataset, HotpotqaDataset, MusiqueDataset, TriviaqaDataset\n",
    "from src.models import RobertaLargeFinetunedRace, LongformerLarge4096AnsweringRace, RobertaBaseSquad2, Chatglm6bInt4, Chatglm26bInt4\n",
    "from src.pipelines import RacePipeline, DreamPipeline, SquadPipeline\n",
    "from src.tools.easy import initialize_logger, terminate_logger, load_args\n",
    "from src.modules import CoMatch\n",
    "\n",
    "from src.tests import comatch_testscript, dcmn_testscript, duma_testscript, hrca_testscript, attention_testscript\n",
    "print(f\"当前工作目录: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试dataset.yield_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:50:28.711653Z",
     "start_time": "2024-10-08T12:48:32.725595Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_yield_batch():\n",
    "    # data_dir = r\"D:\\data\"\t# Lab PC\n",
    "    # data_dir = r\"D:\\resource\\data\"\t# Region Laptop\n",
    "    data_dir = DATA_DIR\t# default\n",
    "    data_dir_race = DATA_SUMMARY[\"RACE\"][\"path\"]\n",
    "    data_dir_dream = DATA_SUMMARY[\"DREAM\"][\"path\"]\n",
    "    data_dir_squad = DATA_SUMMARY[\"SQuAD\"][\"path\"]\n",
    "    data_dir_hotpotqa = DATA_SUMMARY[\"HotpotQA\"][\"path\"]\n",
    "    data_dir_musique = DATA_SUMMARY[\"Musique\"][\"path\"]\n",
    "    data_dir_triviaqa = DATA_SUMMARY[\"TriviaQA\"][\"path\"]\n",
    "\n",
    "    # RACE\n",
    "    def _test_race():\n",
    "        print(_test_race.__name__)\n",
    "        dataset = RaceDataset(data_dir=data_dir_race)\n",
    "        for batch in dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"], difficulties=[\"high\"]):\n",
    "            pass\n",
    "    # DREAM\n",
    "    def _test_dream():\n",
    "        print(_test_dream.__name__)\n",
    "        dataset = DreamDataset(data_dir=data_dir_dream)\n",
    "        for batch in dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"]):\n",
    "            pass\n",
    "    # SQuAD\n",
    "    def _test_squad():\n",
    "        print(_test_squad.__name__)\n",
    "        dataset = SquadDataset(data_dir=data_dir_squad)\n",
    "        versions = [\"1.1\"]\n",
    "        types = [\"train\", \"dev\"]\n",
    "        for version in versions:\n",
    "            for type_ in types:\n",
    "                for i, batch in enumerate(dataset.yield_batch(batch_size=2, type_=type_, version=version)):\n",
    "                    if i > 5:\n",
    "                        break\n",
    "                    print(batch)\n",
    "    # HotpotQA\n",
    "    def _test_hotpotqa():\n",
    "        print(_test_hotpotqa.__name__)\n",
    "        dataset = HotpotqaDataset(data_dir=data_dir_hotpotqa)\n",
    "        filenames = [\"hotpot_train_v1.1.json\",\n",
    "                     \"hotpot_dev_distractor_v1.json\",\n",
    "                     \"hotpot_dev_fullwiki_v1.json\",\n",
    "                     \"hotpot_test_fullwiki_v1.json\",\n",
    "                     ]\n",
    "        for filename in filenames:\n",
    "            for i, batch in enumerate(dataset.yield_batch(batch_size=2, filename=filename)):\n",
    "                if i > 5:\n",
    "                    break\n",
    "                print(batch)\n",
    "    # Musique\n",
    "    def _test_musique():\n",
    "        print(_test_musique.__name__)\n",
    "        batch_size = 2\n",
    "        dataset = MusiqueDataset(data_dir=data_dir_musique)\n",
    "        types = [\"train\", \"dev\", \"test\"]\n",
    "        categories = [\"ans\", \"full\"]\n",
    "        answerables = [True, False]\n",
    "        for type_ in types:\n",
    "            for category in categories:\n",
    "                if category == \"full\":\n",
    "                    for answerable in answerables:\n",
    "                        print(f\"======== {type_} - {category} - {answerable} ========\")\n",
    "                        for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category, answerable)):\n",
    "                            if i > 5:\n",
    "                                break\n",
    "                            print(batch)\n",
    "                else:\n",
    "                    print(f\"======== {type_} - {category} ========\")\n",
    "                    for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category)):\n",
    "                        if i > 5:\n",
    "                            break\n",
    "                        print(batch)\n",
    "\n",
    "    # TriviaQA\n",
    "    def _test_triviaqa():\n",
    "        print(_test_triviaqa.__name__)\n",
    "        n = 1\n",
    "        batch_size = 2\n",
    "        dataset = TriviaqaDataset(data_dir=data_dir_triviaqa)\n",
    "        types = [\"verified\", \"train\", \"dev\", \"test\"]\n",
    "        categories = [\"web\", \"wikipedia\"]\n",
    "        for type_ in types:\n",
    "            for category in categories:\n",
    "                print(f\"======== {type_} - {category} ========\")\n",
    "                for i, batch in enumerate(dataset.yield_batch(batch_size, type_, category, False)):\n",
    "                    if i > n:\n",
    "                        break\n",
    "                    print(batch[0][\"question\"], batch[0][\"answers\"])\n",
    "        gc.collect()\n",
    "        for type_ in types[1:]:\n",
    "            print(f\"======== {type_} - unfiltered ========\")\n",
    "            for i, batch in enumerate(dataset.yield_batch(batch_size, type_, \"web\", True)):\n",
    "                if i > n:\n",
    "                    break\n",
    "                print(batch[0][\"question\"], batch[0][\"answers\"])\n",
    "\n",
    "    # Test\n",
    "    logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "#     _test_race()\n",
    "#     _test_dream()\n",
    "#     _test_squad()\n",
    "#     _test_hotpotqa()\n",
    "#     _test_musique()\n",
    "    _test_triviaqa()\n",
    "    terminate_logger(logger)\n",
    "\n",
    "test_yield_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试model.generate_model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:54:10.485101Z",
     "start_time": "2024-10-08T12:54:08.592621Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_generate_model_inputs():\n",
    "\n",
    "    def _test_race():\n",
    "        print(_test_race.__name__)\n",
    "        data_dir = DATA_SUMMARY[RaceDataset.dataset_name][\"path\"]\n",
    "        model_path = MODEL_SUMMARY[RobertaLargeFinetunedRace.model_name][\"path\"]\n",
    "        # model_path = MODEL_SUMMARY[LongformerLarge4096AnsweringRace.model_name][\"path\"]\n",
    "        dataset = RaceDataset(data_dir)\n",
    "        model = RobertaLargeFinetunedRace(model_path, device=\"cpu\")\n",
    "        # model = LongformerLarge4096AnsweringRace(model_path, device=\"cpu\")\n",
    "\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"], difficulties=[\"high\"])):\n",
    "            model_inputs = RaceDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    def _test_dream():\n",
    "        print(_test_dream.__name__)\n",
    "        data_dir = DATA_SUMMARY[DreamDataset.dataset_name][\"path\"] \n",
    "        model_path = MODEL_SUMMARY[RobertaLargeFinetunedRace.model_name][\"path\"]\n",
    "        dataset = DreamDataset(data_dir)\n",
    "        model = RobertaLargeFinetunedRace(model_path, device=\"cpu\")\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, types=[\"train\", \"dev\"])):\n",
    "            model_inputs = DreamDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    def _test_squad():\n",
    "        print(_test_squad.__name__)\n",
    "        data_dir = DATA_SUMMARY[SquadDataset.dataset_name][\"path\"]\n",
    "        model_path = MODEL_SUMMARY[RobertaBaseSquad2.model_name][\"path\"]\n",
    "        dataset = SquadDataset(data_dir)\n",
    "        model = RobertaBaseSquad2(model_path, device=\"cpu\")\n",
    "\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, type_=\"dev\", version=\"1.1\")):\n",
    "            model_inputs = SquadDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\n",
    "\n",
    "    def _test_hotpotqa():\n",
    "        print(_test_hotpotqa.__name__)\n",
    "        data_dir = DATA_SUMMARY[HotpotqaDataset.dataset_name][\"path\"]\n",
    "        model_path = MODEL_SUMMARY[Chatglm26bInt4.model_name][\"path\"]\n",
    "        dataset = HotpotqaDataset(data_dir)\n",
    "        model = Chatglm6bInt4(model_path, device=\"cuda\")\n",
    "        for i, batch in enumerate(dataset.yield_batch(batch_size=2, filename=\"dev_distractor_v1.json\")):\n",
    "            model_inputs = HotpotqaDataset.generate_model_inputs(batch, model.tokenizer, model.model_name, max_length=512)\n",
    "            print(model_inputs)\n",
    "            print('-' * 32)\n",
    "            model_inputs = model.generate_model_inputs(batch, max_length=32)\n",
    "            print(model_inputs)\n",
    "            print('#' * 32)\n",
    "            if i > 5:\n",
    "                break\t\t\n",
    "\n",
    "    logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "    _test_race()\n",
    "    _test_dream()\n",
    "    _test_squad()\n",
    "    _test_hotpotqa()\n",
    "    terminate_logger(logger)\n",
    "\n",
    "test_generate_model_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试pipeline.easy_inference_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference_pipeline():\n",
    "\n",
    "    def _test_race():\n",
    "        race_pipeline = RacePipeline()\n",
    "        pipeline = race_pipeline.easy_inference_pipeline(\n",
    "            dataset_class_name = \"RaceDataset\",\n",
    "            model_class_name = \"RobertaLargeFinetunedRace\",\n",
    "            batch_size = 2,\n",
    "            dataset_kwargs = {\"types\": [\"train\"], \"difficulties\": [\"high\", \"middle\"]},\n",
    "            model_kwargs = {\"max_length\": 512},\n",
    "        )\n",
    "\n",
    "    def _test_squad():\n",
    "        squad_pipeline = SquadPipeline()\n",
    "        pipeline = squad_pipeline.easy_inference_pipeline(\n",
    "            dataset_class_name = \"SquadDataset\",\n",
    "            model_class_name = \"RobertaBaseSquad2\",\n",
    "            batch_size = 2,\n",
    "            dataset_kwargs = {\"type_\": \"train\", \"version\": \"2.0\"},\n",
    "            model_kwargs = {\"max_length\": 512},\n",
    "        )\n",
    "\n",
    "    # logger = initialize_logger(os.path.join(LOG_DIR, \"sanity.log\"), 'w')\n",
    "    _test_race()\n",
    "    # _test_squad()\n",
    "    # terminate_logger(logger)\n",
    "    \n",
    "    \n",
    "test_inference_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T03:15:57.480400Z",
     "start_time": "2024-10-17T03:15:57.455056Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T03:15:59.023854Z",
     "start_time": "2024-10-17T03:15:58.481446Z"
    }
   },
   "outputs": [],
   "source": [
    "comatch_testscript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T03:16:11.208402Z",
     "start_time": "2024-10-17T03:16:10.505657Z"
    }
   },
   "outputs": [],
   "source": [
    "dcmn_testscript()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-adapters-jupyter",
   "language": "python",
   "name": "py39-adapters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
